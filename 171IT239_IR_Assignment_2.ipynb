{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "171IT239_IR_Assignment_2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNfhPbSKnW/Oq86gcM2QdHj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17shashank17/IR_Assignment_2/blob/main/171IT239_IR_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvJlOvszHLNO"
      },
      "source": [
        "**Please Run Code block by block**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAbkbzbi0Sfe"
      },
      "source": [
        "# !pip install wikipedia==1.4.0\n",
        "import wikipedia\n",
        "\n",
        "wikipedia.set_lang(\"en\")\n",
        "\n",
        "\n",
        "with open(\"cityInIndia.txt\",\"r\") as fr:\n",
        "    for line in fr:\n",
        "        city = line.strip()\n",
        "        print(city)\n",
        "        page = wikipedia.summary(city)\n",
        "        with open(f'corpus/{city}.txt', 'w',encoding = \"utf-8\") as fw:\n",
        "            print(page)\n",
        "            fw.write(page)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcQot2kK256B"
      },
      "source": [
        "Generates the dataset of each cities which is there in **cityInIndia.txt** file and save the content in corpus folder with filename as **{city_name}.txt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9Y42PDwAStV",
        "outputId": "7bb2652c-77f3-492f-ee02-09fb0f6bafd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "from collections import defaultdict\n",
        "# import nltk\n",
        "# nltk.download(\"punkt\")\n",
        "# nltk.download(\"wordnet\")\n",
        "# nltk.download(\"stopwords\")\n",
        "\n",
        "total_tokens = 0\n",
        "\n",
        "class DocumentInfo:\n",
        "\n",
        "\t\"\"\"\n",
        "\t\tDefined data structure for storing document details\n",
        "\t\"\"\"\n",
        "\n",
        "\tdocument_id = 1\n",
        "\tdef __init__(self,title,text,tokens=None,length_of_tokens=None):\n",
        "\t\tself.id = DocumentInfo.document_id\n",
        "\t\tself.title = title\n",
        "\t\tself.text = text\n",
        "\t\tself.tokens = tokens\n",
        "\t\tself.length_of_tokens = length_of_tokens\n",
        "\t\tDocumentInfo.document_id += 1\n",
        "\n",
        "\tdef __str__(self):\n",
        "\t\treturn self.title\n",
        "\n",
        "def tokenization(text):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\tReturns all the tokens in the text. Basically split the whole document on occurrence of space\n",
        "\t\"\"\"\n",
        "\n",
        "\n",
        "\t# stop_words = set(stopwords.words('english'))\n",
        "\ttokens = word_tokenize(text)\n",
        "\n",
        "\t# tokens = [word for word in result if not word in stop_words]\n",
        "\treturn tokens\n",
        "\n",
        "\n",
        "def stopwords_removal(tokens):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\tRemove all the stopwords like preposition, conjuntion articles etc from the token list\n",
        "\t\"\"\"\n",
        "\n",
        "\tnew_tokens = []\n",
        "\tstop_words = set(stopwords.words('english'))\n",
        "\tnew_tokens = [word for word in tokens if not word in stop_words]\n",
        "\treturn new_tokens\n",
        "\n",
        "def normalization(text):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\tRemove all the whitespaces, numbers and punctuation marks from the text and returns the new text\n",
        "\t\"\"\"\n",
        "\ttext = convert_to_lower_case(text)\n",
        "\ttext = remove_number_whitespace_punctuation(text)\n",
        "\treturn text\n",
        "\n",
        "def stemming(tokens_array):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\treduces inflected words to their root. Porter Stemmer method from nltk library has been used to do so\n",
        "\t\"\"\"\n",
        "\tps = PorterStemmer()\n",
        "\tfor i in range (len(tokens_array)):\n",
        "\t\ttokens_array[i] = ps.stem(tokens_array[i])\n",
        "\n",
        "\treturn tokens_array\n",
        "\n",
        "def lemmatization(tokens_array):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\treduces inflected words to their root on the basis of context. \n",
        "\t\tWordNetLemmatizer method from nltk library has been used to do so\n",
        "\t\"\"\"\n",
        "\tlemmatizer = WordNetLemmatizer()\n",
        "\tfor i in range(len(tokens_array)):\n",
        "\t\ttokens_array[i] = lemmatizer.lemmatize(tokens_array[i])\n",
        "\treturn tokens_array\n",
        "\n",
        "\n",
        "def convert_to_lower_case(text):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\tconvert all the letters from the text to lower case\n",
        "\t\"\"\"\n",
        "\n",
        "\treturn text.lower()\n",
        "\n",
        "def remove_number_whitespace_punctuation(text):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\tremove all the whitespaces and punctuation marks\n",
        "\t\"\"\"\n",
        "\n",
        "\ttext = re.sub(r'\\d+', '', text)\n",
        "\ttext = text.strip()\n",
        "\ttext = text.translate(str.maketrans('','', string.punctuation))\n",
        "\treturn text\n",
        "\n",
        "def generate_tokens(text):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\tHere, all the preprocessing steps are applied and finally the tokens are returned.\n",
        "\t\"\"\"\n",
        "\ttext = normalization(text)\n",
        "\ttokens = tokenization(text)\n",
        "\t# tokens = stemming(tokens)\n",
        "\ttokens = lemmatization(tokens)\n",
        "\ttokens = stopwords_removal(tokens)\n",
        "\n",
        "\treturn tokens\n",
        "\n",
        "def readDocumentAndGetTokens():\n",
        "\n",
        "\t\"\"\"\n",
        "\t\tAll the documents from the corpus folder are read and content of each document is is tokenized \n",
        "\t\tand saved in DocumentInfo Object.\n",
        "\t\"\"\"\n",
        "\n",
        "\tpath = 'corpus'\n",
        "\tobj_array = []\n",
        "\tfor filename in glob.glob(os.path.join(path, '*.txt')):\n",
        "\t\twith open(os.path.join(os.getcwd(), filename), 'r', encoding = \"utf-8\") as f:\n",
        "\t\t\t# array.append(f.read())\n",
        "\t\t\tobj = DocumentInfo(filename,f.read())\n",
        "\t\t\tobj_array.append(obj)\t\n",
        "\n",
        "\tfor obj in obj_array:\n",
        "\t\tif obj.text != None:\n",
        "\t\t\tobj.tokens = generate_tokens(obj.text)\n",
        "\t\t\tobj.length_of_tokens = len(obj.tokens)\n",
        "\n",
        "\treturn obj_array\n",
        "\n",
        "def get_all_tokens(obj_array):\n",
        "\n",
        "    tokens = []\n",
        "    for obj in obj_array:\n",
        "        tokens+=obj.tokens\n",
        "\n",
        "    tokens = list(set(tokens))\n",
        "    tokens.sort()\n",
        "    return tokens\n",
        "\n",
        "obj_array = readDocumentAndGetTokens()\n",
        "tokens = get_all_tokens(obj_array)\n",
        "no_of_doc = len(obj_array)\n",
        "print(\"total number of tokens\", len(tokens))\n",
        "tokens = tokens[:3230]\n",
        "\n",
        "for i in range(len(tokens)):\n",
        "    print(tokens[i], end = \" \")\n",
        "    if i % 17 == 0:\n",
        "        print(\"\\n\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total number of tokens 3270\n",
            "abbreviated \n",
            "\n",
            "abbreviation abd abhiyan ablution abode abolish abolished abortive academic academy acceded accepted accessing accorded according account accounting \n",
            "\n",
            "achieved achievement across act active activity ad adda added additional adi adil adjoin adjoining adjudged adkic administered \n",
            "\n",
            "administers administrates administration administrative administratively administrator advantage aeronautics aerospace affair afghan afri agastyamala age agency agglomerated agglomeration \n",
            "\n",
            "agglomerationsolapur agra agri agricultural ahead ahmad ahmadnagar ahmedabad aiims air airpolluted airport aiya aizawl ajanta ajayameru ajayaraja \n",
            "\n",
            "aji ajmer akbar ala alakha alang alauddin albert ali aligarh allahabad allowance allows alloy allygurh almost along \n",
            "\n",
            "alongside alpha alqadir also altajir alternative although altitude alupas alwar always amalgamation amavasai ambadevi ambar ambarsar ambassador \n",
            "\n",
            "ambedkar ambience ambitious american ammunition among amongst amount ampri amravati amritsar anchar anchuthengu ancient andhra anglicised anglomysore \n",
            "\n",
            "anglooriental animal anna annexed annual annually anthropological antiquity apcrda approximately april aquatic arabian arabic aravali aravalli arc \n",
            "\n",
            "archaeological archaeologically archeological architect architectural architecture area areait arearanchi arid arikamedu arm army aromatic around arrangement art \n",
            "\n",
            "article artificial artisan artistic aryabhata asaf asansol ascribed ashram ashtamudi ashtbhuja asia asian asiatic asics assam assembly \n",
            "\n",
            "associate associated association assumed astikagrama astronomer astronomic atri atrisuta attain attempt attention attract attracted attraction attracts augmentation \n",
            "\n",
            "august auli aurangabad aurangzeb auric authority auto automobile availability available avanti average awadh away ays ayurveda b \n",
            "\n",
            "baba babasaheb babur back backare backwater bada badaun badauni badrinath bagalkote bagh bahadur bahmani baji baker bakery \n",
            "\n",
            "bakhsh balcony ballari banaras bangalore bangalorekarnataka bangaluru bangladesh bangle bank bankhandi banking banmore banyan banāras bara barabanki \n",
            "\n",
            "barabati bardhaman bareilly barley baroda barrage base based basic basilica basin basis basistha basmati battle battuta bauna \n",
            "\n",
            "bay bazaar bbc bc bce bce–nd beach bear beautiful became become beedi began begin beginning begur behind \n",
            "\n",
            "belagavi belgaum believe believed bellary benares bench bengal bengali bengaluru bengalūru besides besieged best betalevel betel betwa \n",
            "\n",
            "beyond bhagalpur bhakti bhangarh bharat bharatiya bhatinda bhavan bhavnagar bhavsinhji bhedaghat bhel bhilai bhilai–durg bhilwara bhind bhiwandi \n",
            "\n",
            "bhiwandinizampur bhopal bhopalbhopal bhosale bhu bhubaneswar bhubaneswars bhumihar bibi bifurcated biggest bihar bijapur bika bikaner bilaspur billion \n",
            "\n",
            "billionaire biluakhai bin biosphere biotechnology bird birthplace birupa bishop blue bmp board boardrohtak bodh bodri body bollywood \n",
            "\n",
            "bombay boom boost border bordered bordering born bose botanical boundary bounded braganza brahmani brahmaputra brahmin braiding braj \n",
            "\n",
            "branch brand brass brassware break brics brief bright britain british britishheld broader brought btsso buddha buddhism buddhist \n",
            "\n",
            "budha bugyal building buildingsthe built bulandshahr bull bundelkhand burdwan bureau burhi bus business bustard bylanes bəˈnaːrəs bʱoːpaːl \n",
            "\n",
            "c calculation calcutta calendar called came campaign camping campus canal cancer candra canton cantonment capacity capital capitalmumbai \n",
            "\n",
            "capitol captured caput caravan carbide cargo carnatic carpet carried carrying carved carving cashew caste casting castle castoff \n",
            "\n",
            "categorised catherine cauvery cave cazri ce ceajmer ceded celebrated celebration census censusestimated cent center central centrally centre \n",
            "\n",
            "centred century cereal ce–th chadar chahamana chain chairman chakki chakrata challenge chalukyas chamba chambal chamundi chanakya chanda \n",
            "\n",
            "chandigarh chandra chandragupta change changed char characterised characterized chariot charit charles charminar chauhan cheap chemical chennai chera \n",
            "\n",
            "cheras cheroot chess chessboard chhatrapati chhattisgarh chidambaram chidambaranar chief chieftain chikkadevaraja child chilli china chinchwad chinese chinnamalai \n",
            "\n",
            "chintpurni chitranjali chittirai chittoor chittorgarh chola cholas chopta chosen chota choudwar chowpati chozhas church cigar cinema circle \n",
            "\n",
            "circuit cishindon citing citizenship city cityjhansi citysystems civic civil clan class classed classical classification classified clay cleanest \n",
            "\n",
            "cleanliness climate close closeknit closely clothing cloud club cluster coal coalfield coast coastal cochin coconut coffee coimbatore \n",
            "\n",
            "coin collect collected collectively college colloquially colonial colourful combined combining come command commandvisakhapatnams commerce commercial commission commissionary \n",
            "\n",
            "commissioner common commonly commonwealth communication community commuter company competition complete completed complex component composed comprises comprising conducted \n",
            "\n",
            "confederation conference confluence congregation congress connect connected connecting connectivity conquered conquest consecutive consequently conservation considered consisting consonantal \n",
            "\n",
            "consort constituency constitute constitutes constructed construction container containing contains contention continent continental continued continues continuing continuously contributed \n",
            "\n",
            "contributes contributing contribution contributor control controlled convenient conversation cool cooler copious cora corbusier core coromandel corp corporate \n",
            "\n",
            "corporation corridor cosmetic cosmopolitan cotton coulão council counter countermagnet country course court courtyard covai cover covering craft \n",
            "\n",
            "created creation creative cremate cremated cricket cricketing crime critical crop crowd cuisine cultural culture cup current currently \n",
            "\n",
            "cuttack cybercafe cycle dainik dakshina dal dalhousie dalma dar darjeeling dasara dashashwamedh data date dating daulatabad day \n",
            "\n",
            "dayara de dead deadly debate decade deccan december decided decision declared decline declined deco dedicated deep defeat \n",
            "\n",
            "defeated defence dehradun dehradundehradun dehu deity delhi delhikalka delhi–sonipat–panipat delta demand demise democracy demographically den densely deo \n",
            "\n",
            "departmental depicted deputy dera derives descended described desert design designated designed desinganadu desinganadus destination destinationsbhubaneswar destiny detroit \n",
            "\n",
            "deva develop developed development devi devotion devrahwa dham dhanaulti dhanbad dhanbaddhanbad dharamshala dharapuram dharma dharwad dheeran dhopeshwar \n",
            "\n",
            "dhuandhar dialect diamond diesel different differs dillī direction director dirtiest disadvantage disaster discovered dish display dispur distance \n",
            "\n",
            "distinct distinctive distinctively distributary distributed district district—the diverse divided division divisional divisiondhanbad dmathe dmic dmrc doab dodital \n",
            "\n",
            "doe dolphin domar dombivli domestic dominant dominion done doobraj doodh doon dosa doulgovinda dow downtown dowry dr \n",
            "\n",
            "drainage drdo drew dried drishadvati driven drona drop dsrrau dubbed due dugong dun durbar durg durga durjaya \n",
            "\n",
            "dutch dying dynasty dynastygoverned dēhlī dēvagirī dʒəbəlˈpʊɾ earlier earliest early earned earth earththe ease easiest east eastern \n",
            "\n",
            "eastshillong east–west economic economy edge education educational edwin effective eg eight eighth eighthhighest either ekamra elect elected \n",
            "\n",
            "election electricals electricity electronic electronics elephant elephanta elevation eleven eligible ellora elxsi embankment embassy emblem emerged emerging \n",
            "\n",
            "emperor empire empirein employ employed employment encircled encompassing encouraged end endangered energy enforcement engaged engineer engineering england \n",
            "\n",
            "english enough ensemble entertainment entire entity entrance environment epic eponymous equatorial equipment equipped era erode especially essential \n",
            "\n",
            "establish established establishment estate estimate estimated etah etawah ethiopian ethnic european event eventually evergreen every evident evolved \n",
            "\n",
            "exact excavation exchange exchanged excise excluding executes executive exist existed existing expanded expanse expansion expatriate experienced experiencing \n",
            "\n",
            "explosion exponential export exported exporter expressway extant extend extended extension extreme fabric fabrication facilitated facility facto factory \n",
            "\n",
            "fair fall familiar family famous far faridabad farming fashion fast fastest fastestgrowing fasttrack fateh fatehnagar fatehpur father \n",
            "\n",
            "fatima fauna feature featuring february fed federal fell female fertile festival festivity feudal fibrous field fifteenth fifth \n",
            "\n",
            "fifthbusiest fifthlargest fifthmost fighting figure figured filigree film finance financial find fine firoz firozabad first fishery fishing \n",
            "\n",
            "five flagship flight flora flourish flourished flourishing flow flowed flower flowing fluctuating focusing followed follower following fondly \n",
            "\n",
            "food foot football foothill footwear force forefront foreign foremost forest form formally formation formed former formerly forming \n",
            "\n",
            "fort fortified fortress fortunate fought found foundation foundationit founded founder founding four fourteenthmost fourth fourthlargest fourthmost franchise \n",
            "\n",
            "freestyle french frequented fruit fry ft full fullfledged function functioning furnished furniture g gadag gadda gadge gaekwad \n",
            "\n",
            "gaekwads gained gajapati galee gallery game gandak gandhi gandhinagar ganga gangayamuna ganges gangetic gangotri ganthiya gap garden \n",
            "\n",
            "garhwal garment gas gastronomy gate gateway gauhati gaur gautam gave gaya gdp gear gem genealogy generally generating \n",
            "\n",
            "generation geographic geographical geographically geological geology geometric george german get getting ghaggar gharana ghat ghaziabad gi gird \n",
            "\n",
            "girl give given giving glass glassmaking glassware global glory gmc gmda go gobind gohil gol golconda golden \n",
            "\n",
            "gomti good got govardhan governance governed government governmentit governor governorgeneral gowdā gradually gramadevata grammatically grand grandeur grandly \n",
            "\n",
            "granite grant granted grape great greater greatest greatly greek green greenest greenfield greenwich grenadier grew grid grinder \n",
            "\n",
            "grishneshwar gross ground group grow growing grown growth gujarat gujarati gulf guman gumbaz gun guntur gupta gurdaspur \n",
            "\n",
            "gurgaon guru gurudwaras guwahati gwalior gwaliors ha haider hail hair hal halegannada half halwa hand handicraft handle \n",
            "\n",
            "handloom hanuman happ happiest happiness hapur har harbour hard hardoi hare haridwar haridwardehradun harishchandra harmandir harsil haryana \n",
            "\n",
            "haryanka hastinapur hathras havelis haveri head headed headgear heading headquarter headquartered headquarters health healthcare heavy height held \n",
            "\n",
            "help helped helper hence henna herbert herejabalpur heritage high highest highly highway hill hillsthe hilly himachal himalaya \n",
            "\n",
            "himalayan himayat hindi hindon hindu hinduism hindustan hindustani hisar hisarefiroza hissar historic historical historically history hitec hockey \n",
            "\n",
            "holiest holkar holy home homeopathic honour hooghly hornby horticultural hospital host hosted hosting hot hotel hottest house \n",
            "\n",
            "houseboat housed housing however hra hriday hub hubballi hubballidharwad hubli hublidharwad huge human hundred hussain hyder hyderabad \n",
            "\n",
            "hydərəbaad iast iastbēḷagāma ibn ibrahim identified idiosyncrasy ie ii iifm iiit iiitb iim iimb iisc iiser iit \n",
            "\n",
            "ilahabad ilahabas illahabad imperial imphal implementation importance important impressed improve inaugural inaugurated inception include included includes including \n",
            "\n",
            "inclusion income incorporated increasing increasingly independence independencelocated independent index india indiachennai indiadelhi indiagwalior indiain indian indiathe indiathoothukudi \n",
            "\n",
            "india—and indication indigenous indigenouslyrun indira indore indores indu indus industrial industrialisation industriesmadurai industry induvaasaram influence influenced information \n",
            "\n",
            "infosys infotainment infrastructure inhabited initially initiating initiative ink inland inscription inside installation institute institution integrated intention interchangeably \n",
            "\n",
            "intercity interdisciplinary interest intermittent international internationally interregnum interruption intersection intersectseven interstate introduced introducing introduction investment invincible involving \n",
            "\n",
            "ipa irrigation irwin island isocyanate ispat isro isros ist istanbul iv ivory jabalpur jagannath jagran jah jahan \n",
            "\n",
            "jahangir jahangirakbarnama jahi jahis jain jainism jaintia jaipur jalandhar jalpaiguri jama jambukeswarar james jammu jamsetji jamshedpur janaagraha \n",
            "\n",
            "janamastmi janata jane janmashtami janmasthan jantar january jardalu jasmine jat jewel jewellery jhansi jhansijhansi jharkhand jhelum jnpt \n",
            "\n",
            "jodhpur joint jointly jolly jrd jubbulpore judicial july junction june junk jure jutti jwalaji jyotirlinga k ka \n",
            "\n",
            "kabir kabul kachchhapaghatas kadambas kakatiya kakatiyas kala kalachuri kalaga kali kalinga kalingan kalpasutra kalyan kalyandombivli kalyani kamakhya \n",
            "\n",
            "kaman kamaraj kamarupa kamdev kanaiyalal kandarpur kangla kangra kannada kanpur kansa kanyakumari karachi karamjit karanataka karnataka karwar \n",
            "\n",
            "kasganj kashi kashmir kashmiri kataka katarni katehar kathajodi kattabomman kautilya kaveri kavi kazhakoottom kdmc kedarkantha kedarnath kegaon \n",
            "\n",
            "keladi kempé kept kerala kesava khadki khalji khambhat khan kharar kharkai khasi khaḍkī khoh khokhrakot khorda ki \n",
            "\n",
            "kilometer kilometre kind kinfra king kingdom km kmc knit known koel kol kolhapur kolhapurogg koli kolkata kollam \n",
            "\n",
            "konark konda kongu konkan korekeni kosa kosambi kota kovai kovalam koɭɭəm kpmg krishna kshetra kshetras kshipra kuakhai \n",
            "\n",
            "kublai kumari kumbh kupwad kupwadalong kurali kurnool kuru kv königsberger kāśī laboratory labour lac laccadive lady lahore \n",
            "\n",
            "laid lake lakh lakhnaū lakshmi lal land landmark landowner landscape lane language large larger largest lashkar last \n",
            "\n",
            "late later laterite latitude launching laureate law le lead leader leading leaf league leaked learning led left \n",
            "\n",
            "legislature lends length letter level lg lgb library licence lie life light like limit limited line link \n",
            "\n",
            "liquor list listed listen lit litchi literally literature litter livable live liveable lived living loan local locally \n",
            "\n",
            "located location locomotive lodi lodis logistical lok lonely long longest longitude look loom looted lord lost lot \n",
            "\n",
            "lotus low ltd lucknow ludhiana lunar lutyens lychee lying mabar machinery maciej madan made madhi madhurye madhya \n",
            "\n",
            "madras madurai magadh magadha magahi magistrate magnet maha mahajanapadas mahakaleshwar mahakoshal mahal mahanadi mahanagara mahananda maharaj maharaja \n",
            "\n",
            "maharana maharashtra mahatma mahavira mahdərye main mainland mainly mainpuri maize majha major majority makar make makerchandra making \n",
            "\n",
            "malabar malanpur malayalam malik mall mallige malwa mammal man manage managed management manages manalur manas manchester mandal \n",
            "\n",
            "mandals mandarin maneklal mangalore mangaluru mango manihar manikarnika manipur manit mannar manonmaniam mansab mantar manual manufacturing many \n",
            "\n",
            "maqbara mar maratha marathi marathispeaking marathon marathwada marble march marco margin marine maritime marked market marriage married \n",
            "\n",
            "marthanda martyr marwar masala masculine masjid mass master masterplanned matas maternal mathematical mathura maurya mauryan maxwell may \n",
            "\n",
            "mayer mayor maze mcleodganj mean meaning measure medical medicine medieval medium meenakshi megasthenes meghalaya mehrangarh mela member \n",
            "\n",
            "memorial men mental mention mentioned mercantile merchant mercury merged merger merging meridian merit mesolithic meter methyl metre \n",
            "\n",
            "metro metropolis metropolitan mewar mewari mhrd mi mid middle midth midway migrant migrated migration milder mile military \n",
            "\n",
            "mill millennium million millionaire millionplus min mine mineral minister ministry miraj mirzapur mission missionpaithan mixture mizo mizoram \n",
            "\n",
            "mmr moat mochan mode moderate modern modernisationchandigarhs modi modis mohali mohammed mohan mohua monday monsoon monument monumental \n",
            "\n",
            "moon moradabad morar morena mosque mostly mostvisited motion motorcycle moud mould mound mountain move moved movement moving \n",
            "\n",
            "mubarak much mud mughal mughalera mughals muhammad muhammadan mulberry multicuisine multicultural multinational multinationals mumbai municipal municipality munshi \n",
            "\n",
            "murad museum musi music musical musician muslim muslin mussoorie mussorie mutha muzaffarnagar muzaffarpur muziris mysore mysticism mysuru \n",
            "\n",
            "mythological mythology nadu nagam nagar nagari nageshwara nagpur nagri nalanda nam name named namely namesake nanak nanda \n",
            "\n",
            "nandidhwaj naraj narendra narengi naresh naseer nasir nasira nath nation national nationalism nationwide natural nature navagraha naval \n",
            "\n",
            "navel navrtaras navy nawab nayak nayaks naī naṣīr ncr nct ncts nd nda ndfastestgrowing ne near nearby \n",
            "\n",
            "nearest nearly need neighboring neighbourhood neighbouring nelcynda nellai nellaiappar nellore nestled netaji network networka neuroscience new newest \n",
            "\n",
            "newly newlyformed newtehri next nh nickname nicknamed nid nift nigam night nimhans nine nineteen nineteenth ninth ninthbest \n",
            "\n",
            "nirf nishakara nit nizam nizams nizamuddin nlcp nliu nlsiu nlu nobel nobleman node noida nominally nongovernmental north \n",
            "\n",
            "northeast northeastern northerly northern northernmost northernplains northwest northwestern north–south notable notably note noted november nowicki noyyal nr \n",
            "\n",
            "nrcp ntpc nuclear nucleus number numerous nyari nyayadhani nāṣir nāṣira nṣr obtain occupation occupied occupies occupying ocean \n",
            "\n",
            "october odia odisha office official officially oft often oilseed old oldest one onethird oomrawutty open opensignal operates \n",
            "\n",
            "operating operation opportunity ordered ordnance organisation organization oriental origin originally originated orissa otto output outside outskirt outsourcing \n",
            "\n",
            "outstanding overall overseas owned oxford paan padmanabhaswamy pahuj painting pak pakistan pala palace palaiyakkarars palakkad palayakkarar palayamkottai \n",
            "\n",
            "palayams palike pallava pallavas palm pan panchakki panchganga panchkula pandavas pandya pandyas panipat panoromic para paranda parganas \n",
            "\n",
            "park parkbeing parliament part participle particular particularly partition party pas paschim pashupati pass passed past pataliputra pathan \n",
            "\n",
            "pathankot patiala patliputra patna patnas patron patronage patronised pavilion pawapuri pay peace pearl peg penetrator penna people \n",
            "\n",
            "per perceived percent perennial perform perfume perhaps period peripheral persian peshwa peshwas pesticide peta petes pharmaceutical phase \n",
            "\n",
            "philosopher phoenician phool phule phulnakhara pichola picture picturesque piece pilgrim pilgrimage pimpri pital place placed plain plan \n",
            "\n",
            "planet planetarium planned planner planning plant planting plaque plateau play played pleasant plus pm pmr poem poet \n",
            "\n",
            "poetry poetrythe point police policy poligar polish political politics polluted pollution polo polygar polytechnic pomegranate ponmudi poona \n",
            "\n",
            "poovar popular popularly populated population populous porbandar porbandars port portion portuguese position post postindependence poultry power practised \n",
            "\n",
            "pradesh pragjyotishpura prasarak pratap prayag prayaga prayagraj predated predating premier prepared presence present presentday presidency president prestigious \n",
            "\n",
            "previously primarily primary primate prime prince princely principal prior prison privileged process processing procession produced producer product \n",
            "\n",
            "production productive professional program project prominent pronounced pronunciation proper proposed prosperous protected proth provide provides province provincethe \n",
            "\n",
            "provincial proximity public published publisher puja pune punjab punjabi punpun purba puri puɳe python qila qualified quality \n",
            "\n",
            "quantity quilon quli qutb radhakrishnan raebareli raichursolapur rail railway raipur raj raja rajasthan rajasthani rajgir rajgond rajkot \n",
            "\n",
            "rajput rajputana rajputera ram rama rameswaram ramganga ramgarh ramnagar ranbirsingh ranchi ranganathaswamy range rangsagar rank ranked ranking \n",
            "\n",
            "ransacked rao rapid rare rashtrapati rashtriya rated ratlam ratnapuri ravidas ravidassia rayalaseema rd rdmost real reason rebellion \n",
            "\n",
            "rebirth rebuilt received receives recent reclamation recognised reconciled record recorded recycling reddy refer reference referred reflects refrigerator \n",
            "\n",
            "regarded regiment region regional register registered reign reincorporated related relatively released relic religious remain remained remaining remains \n",
            "\n",
            "reminded renamed renaming rendered renovated rent reopening reorganisation replaced report represented reputation research resembles reserve reshaped residence \n",
            "\n",
            "residency resident residential resolution resource responsibility responsible rest restoration reststop retook returned returning revenue reversed revival revived \n",
            "\n",
            "rhinoceros rice rich rifle right rink rintu rishikesh rising ritual river riverine road roadway robert rock rocket \n",
            "\n",
            "rockfort rocky rohilkhand rohini rohtak role rolling roman romanized romantic root rose roughly round rourkela route row \n",
            "\n",
            "royal rubber ruin rule ruled ruler run rupee rural rush rustam rāmdāspur sabha sabor sachihna sacred safest \n",
            "\n",
            "safety sagar sah saharanpur sahib said sail salem salim salt salute salvation salwar samanta samba sambhal samyukta \n",
            "\n",
            "sanctuary sandal sandy sangam sangli sanjashya sankat sankha sankranti sanskari sanskrit santhal sapta sarabhai sarasvati saree sari \n",
            "\n",
            "sariska sarnath sarvekshan sasti satavahana satellite saurashtra savitribai saw say sayajirao sayed scale scenic scheduled scheme scholar \n",
            "\n",
            "school science scientific scindia scotland scripture sculpture sea seaborne seal seaport season seat seating sec seceded second \n",
            "\n",
            "secondcleanest secondhighest secondlargest secondmost secondmostpopulous secondwealthiest secretariat sect sector sectorsfaridabad seed seen sehore seize seized seizing selected \n",
            "\n",
            "selfsustained selva sent separate separated september serf sermon servant serve served service serving session set setting settled \n",
            "\n",
            "settlement seven seventh seventhmost several severe shadow shah shahi shahjahan shaivites shakambhari shaktaujjain shakumbri shankara share sharif \n",
            "\n",
            "shastri shawl sheikh sher shift shifted shillong shimoga shining shipbreaking shipyard shiva shivaji shivaratri shivyogi shoe sholapur \n",
            "\n",
            "shore short showcase showed shree shri shrine shunga siddheshwar side sidhu sign signal significance significancein significant significantly \n",
            "\n",
            "sikandar sikh sikhism sikri silicon siliguri siliserh silk silkworm silver similar since singh singhbhum single singular sipat \n",
            "\n",
            "sir siraj sirī sisodia sitapur site sits situated six sixteen sixteenth sixth sixthlargest sixthmost size skating slab \n",
            "\n",
            "slave slightly small smaller smart smkmr snack snmc snooker snow soap sobriquet society sociopolitical soft software soil \n",
            "\n",
            "solapur solapuri solapurthe solar sold sole soma someshwar sometimes somvaar son sone sonipat soon sophisticated soudha source \n",
            "\n",
            "south southeast southeastern southern southernmost southesst southwest southwestern sovereign sovereignty spa space span speaking special specially specie \n",
            "\n",
            "spectrum spelling spelt spent spice spinning spiritual spiritually split spoken sport sporting spot spread spreading sq sqkm \n",
            "\n",
            "square srinagar srirangam st stagnationa stand stanes star stark started starting startup state stateowned station status stayed \n",
            "\n",
            "steadily steel stem step still stock stone straddle strategic strategically street stretch strip strong strongly struck structure \n",
            "\n",
            "struggle student studio study studying style subah subarnarekha subcity subcontinent subcontinentpune subhas subsequent subsequently suburb succeeded successive \n",
            "\n",
            "sudama sudden suffered suffices sugar suggest sulaiman sultan sultanate summer summit sundaranar sundargarh supply support supported supreme \n",
            "\n",
            "sur surasena surat suri surma surround surrounded surrounding surroundings survekshan survey sutlej suvarna suzerainty swach swachh swachhta \n",
            "\n",
            "swami swamy swarna swaroop swayam sweet swissfrench switch symbolise syncretic synonymous syriac system tag tahsil taj tajulmasajid \n",
            "\n",
            "take taken talai tall taluka tamil tamilnad tamilnadu tangasseri tangier tapeshwar tasar tasselled tata tawi tax tea \n",
            "\n",
            "team technological technology tehsil telangana telecommunication telugu temple temporary ten tenth tepana term termed terminus terracotta terrain \n",
            "\n",
            "territory text textile tfri th thamirabarani thane thar thatipurgwalior thenthe thereafter thevalakara thfastest third thirdlargest thirdmost thirteenth \n",
            "\n",
            "thirtysixth thiruvanaikaval thiruvananthapuram thlargest tholons thomas thondi thoothukudi thoranam though thousand threatened three threeriver throughout thrown thth \n",
            "\n",
            "thumba tier tierii tiger till timber time timesalong tinnevelly tipu tirhut tirthankara tiruchi tiruchirappalli tirumala tirumalai tirunelveli \n",
            "\n",
            "tirupati tiruppur tirupur tirupurogg title tiɾɯnelʋeːli tobacco tod today together tollywood tomars tomb took toonz top total \n",
            "\n",
            "touch tourism tourismguide tourismled tourist touriststhe towards towel tower town township trace traced tract tractor trade trading \n",
            "\n",
            "traditional traditionthe training transaction transcription transferred transformed transhindon transit transitional translated transmission transport transportation transport—air trap travancore \n",
            "\n",
            "travancorecochin travel traveller treasury tree trekking triangle triangulation tribal tribhuja tributary trichinopoly trichy tricity triggeralthough trip trivandrum \n",
            "\n",
            "trivati triveni tropic tropical trouser trunk trust trz tughlaq tughluq tulsidas tumkur tungabhadra tungnath turban turmeric turning \n",
            "\n",
            "tushita tuticorin twelfthmost twenty twentyfouryear twin twincities two twoarmed tyndis type tyre tārādhipa tʃə̃ɳˈɖiːɡəɽʱ t̪iruʋənən̪t̪əpurəm t̪ɪɾɨppuːr u \n",
            "\n",
            "uametropolitan uccn ucil udai udaipur uddaulah ugratara ujjain ujjains ukbased umananda uncle underground undertook undivided undulating unesco \n",
            "\n",
            "unified union unique unit united university unnao unplanned upcoming upland upon upper uprising uraiyur urban urdu use \n",
            "\n",
            "used using uttar uttara uttarakhand uttarkashi v vad vadodara vaigai vaishali vaishnavite vaishnavites valley value varanasi vardhaman \n",
            "\n",
            "vardhamana variety various varkala varma vasundhara veda vedic veerapandiya vellard venad venerated venetian vengi venkateshwara venkateswara venture \n",
            "\n",
            "venue verb version veterinary viceroy victoria victorian victory vidarbha video vidhana view vijay vijayanagar vijayanagara vijayapura vijayawada \n",
            "\n",
            "vikram vikramshila vila village vindhyachal violence virtually visakhapatnam visakhapatnamchennai vishnu vishwamitri vishwanath visible visit visited visiting visitor \n",
            "\n",
            "viz vizag vizhinjam viśākha vo vrindavan vyaktha vyayam vātsyāyana wa wadia wadiyar wadiyars wagah waged wall war \n",
            "\n",
            "warangal ward wastetoenergy waterfall waterfront way wealth wear weaver weaving well wellarranged wellconnected west western wet wheat \n",
            "\n",
            "wheel white whole wide widely wildlife winter wipro within wodeyar woman wooden word work worked workforce working \n",
            "\n",
            "workshop world worldbesides worldlucknow worldwide worship worst worth would woven writer written wrote wwwbtssoorg wāltair yadava yadavas \n",
            "\n",
            "yamuna yamunotri yard yatra yaudheyas ycategory yclass year yellow ygrade yojana young youngest zero zinc zirakpur "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmXdh4SFCgHH"
      },
      "source": [
        "def write_in_csv(tf_idf_matrix, filename):\n",
        "\n",
        "    with open(f\"{filename}.csv\", \"w\", newline = \"\") as csv_file:\n",
        "        writer = csv.writer(csv_file)\n",
        "        writer.writerow([\"Keyword\"]+[\"d\"+str(i+1) for i in range(len(tf_idf_matrix[\"city\"]))])\n",
        "        for key,value in tf_idf_matrix.items():\n",
        "            writer.writerow([key]+value)\n",
        "\n",
        "    df = pd.read_csv(f'{filename}.csv')\n",
        "    print(df)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56cy3npD3szH",
        "outputId": "18f31d00-fb67-4136-d224-b623d9db5770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "import re\n",
        "import string\n",
        "import json\n",
        "import math\n",
        "import pandas as pd \n",
        "from collections import defaultdict\n",
        "\n",
        "total_tokens = 0\n",
        "import csv\n",
        "\n",
        "\n",
        "def generate_word_frequency(obj_array,tokens):\n",
        "\n",
        "    no_of_doc = len(obj_array)\n",
        "    word_frequency_document_wise = defaultdict(list)\n",
        "    for token in tokens:\n",
        "        for obj in obj_array:\n",
        "            word_frequency_document_wise[token].append(obj.text.lower().count(token))\n",
        "    \n",
        "    return word_frequency_document_wise\n",
        "\n",
        "word_frequency_document_wise = generate_word_frequency(obj_array,tokens)\n",
        "write_in_csv(word_frequency_document_wise, \"word_frequency\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Keyword  d1  d2  d3  d4  d5  d6  ...  d94  d95  d96  d97  d98  d99  d100\n",
            "0      abbreviated   0   0   0   0   0   0  ...    0    0    0    0    0    0     0\n",
            "1     abbreviation   0   0   0   0   0   0  ...    0    0    0    0    0    0     0\n",
            "2              abd   0   0   0   0   0   0  ...    0    0    0    0    0    0     0\n",
            "3          abhiyan   0   0   0   0   0   0  ...    0    0    0    0    0    0     0\n",
            "4         ablution   0   0   0   0   0   0  ...    0    0    0    0    0    0     0\n",
            "...            ...  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   ...\n",
            "3225         young   0   0   0   0   0   0  ...    0    0    0    0    0    0     0\n",
            "3226      youngest   0   0   0   0   0   0  ...    0    0    0    0    0    0     0\n",
            "3227          zero   0   0   0   0   0   0  ...    0    0    0    0    0    0     0\n",
            "3228          zinc   0   0   0   0   0   0  ...    0    0    0    0    0    0     0\n",
            "3229      zirakpur   0   0   0   0   0   0  ...    0    0    0    0    0    0     0\n",
            "\n",
            "[3230 rows x 101 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfqbEGfqCBwB",
        "outputId": "7af8c7a2-8d53-4f45-b67b-73780671fc80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "def generate_term_frequency(word_frequency_document_wise):\n",
        "\n",
        "    term_frequency_document_wise = defaultdict(list)\n",
        "    for key in word_frequency_document_wise.keys():\n",
        "        for i in range(len(word_frequency_document_wise[key])):\n",
        "            if word_frequency_document_wise[key][i] != 0:\n",
        "                term_frequency_document_wise[key].append(round(\n",
        "                    1+math.log(word_frequency_document_wise[key][i],2),2))\n",
        "            else:\n",
        "                term_frequency_document_wise[key].append(0)\n",
        "    \n",
        "    return term_frequency_document_wise\n",
        "\n",
        "term_frequency_document_wise = generate_term_frequency(word_frequency_document_wise)\n",
        "write_in_csv(term_frequency_document_wise,\"term_frequency\")\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Keyword   d1   d2   d3   d4   d5  ...  d95  d96  d97  d98  d99  d100\n",
            "0      abbreviated  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "1     abbreviation  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "2              abd  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3          abhiyan  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "4         ablution  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "...            ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...\n",
            "3225         young  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3226      youngest  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3227          zero  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3228          zinc  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3229      zirakpur  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "\n",
            "[3230 rows x 101 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqelbwmxCDJ_",
        "outputId": "9f9d2b75-03b3-4182-d57f-da5a95fb589f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "def generate_idf(word_frequency_document_wise, no_of_doc):\n",
        "\n",
        "    idf = {}\n",
        "    for key in word_frequency_document_wise.keys():\n",
        "        count = 0\n",
        "        for i in range(len(word_frequency_document_wise[key])):\n",
        "            if word_frequency_document_wise[key][i]>0:\n",
        "                count += 1\n",
        "        if count != 0:\n",
        "            idf[key] = round(math.log(no_of_doc/count,2),2)\n",
        "        else:\n",
        "            idf[key] = 0\n",
        "    return idf\n",
        "\n",
        "def generate_csv(inverse_document_frequency):\n",
        "\n",
        "    with open(\"inverse_document_frequency.csv\",\"w\", newline=\"\") as csv_file:\n",
        "        writer = csv.writer(csv_file)\n",
        "        writer.writerow([\"Keywrod\",\"IDF\"])\n",
        "        for key,value in inverse_document_frequency.items():\n",
        "            writer.writerow([key,value])\n",
        "    \n",
        "    df = pd.read_csv('inverse_document_frequency.csv')\n",
        "    print(df)\n",
        "\n",
        "inverse_document_frequency = generate_idf(word_frequency_document_wise, no_of_doc)\n",
        "generate_csv(inverse_document_frequency)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Keywrod   IDF\n",
            "0      abbreviated  6.64\n",
            "1     abbreviation  6.64\n",
            "2              abd  6.64\n",
            "3          abhiyan  6.64\n",
            "4         ablution  6.64\n",
            "...            ...   ...\n",
            "3225         young  5.64\n",
            "3226      youngest  6.64\n",
            "3227          zero  6.64\n",
            "3228          zinc  6.64\n",
            "3229      zirakpur  6.64\n",
            "\n",
            "[3230 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c72m3ZMCPlT",
        "outputId": "6b89e5ec-c88a-4143-c8a0-c98cf3a954cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "def generate_tf_idf(term_frequency_document_wise, inverse_document_frequency):\n",
        "\n",
        "    tf_idf = defaultdict(list)\n",
        "    for key in term_frequency_document_wise.keys():\n",
        "        for i in range(len(term_frequency_document_wise[key])):\n",
        "            if term_frequency_document_wise[key][i] != \"X\" and inverse_document_frequency[key] != \"X\":\n",
        "                tf_idf[key].append(round(\n",
        "                    term_frequency_document_wise[key][i]*inverse_document_frequency[key],2))\n",
        "\n",
        "            else:\n",
        "                tf_idf[key].append(0)\n",
        "\n",
        "    return tf_idf\n",
        "\n",
        "tf_idf_matrix = generate_tf_idf(term_frequency_document_wise,inverse_document_frequency)\n",
        "write_in_csv(tf_idf_matrix, \"tf_idf\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Keyword   d1   d2   d3   d4   d5  ...  d95  d96  d97  d98  d99  d100\n",
            "0      abbreviated  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "1     abbreviation  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "2              abd  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3          abhiyan  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "4         ablution  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "...            ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...\n",
            "3225         young  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3226      youngest  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3227          zero  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3228          zinc  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3229      zirakpur  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "\n",
            "[3230 rows x 101 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EArDKe-QKMdB",
        "outputId": "7ce0c7a1-0ec1-4a70-ebe1-f5200cfb9fe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# effect on term frequency by using double normalization\n",
        "\n",
        "def generate_term_frequency(word_frequency_document_wise, normalization_constant):\n",
        "\n",
        "    term_frequency_document_wise = defaultdict(list)\n",
        "    for key in word_frequency_document_wise.keys():\n",
        "        for i in range(len(word_frequency_document_wise[key])):\n",
        "            if word_frequency_document_wise[key][i] != 0:\n",
        "                term_frequency_document_wise[key].append(round(\n",
        "                    normalization_constant + normalization_constant * \n",
        "                    word_frequency_document_wise[key][i]/max(word_frequency_document_wise[key]),2))\n",
        "            else:\n",
        "                term_frequency_document_wise[key].append(0)\n",
        "    \n",
        "    return term_frequency_document_wise\n",
        "\n",
        "normalization_constant = 0.5\n",
        "term_frequency_document_wise_normalization = generate_term_frequency(word_frequency_document_wise, normalization_constant)\n",
        "write_in_csv(term_frequency_document_wise,\"term_frequency_normalization\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Keyword   d1   d2   d3   d4   d5  ...  d95  d96  d97  d98  d99  d100\n",
            "0      abbreviated  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "1     abbreviation  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "2              abd  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3          abhiyan  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "4         ablution  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "...            ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...\n",
            "3225         young  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3226      youngest  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3227          zero  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3228          zinc  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3229      zirakpur  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "\n",
            "[3230 rows x 101 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUqFgUvNNfY7",
        "outputId": "872d5002-44ea-4399-cb8e-a1929fb4df1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# effect on idf by using inv frequency smooth\n",
        "\n",
        "def generate_idf(word_frequency_document_wise, no_of_doc):\n",
        "\n",
        "    idf = {}\n",
        "    for key in word_frequency_document_wise.keys():\n",
        "        count = 0\n",
        "        for i in range(len(word_frequency_document_wise[key])):\n",
        "            if word_frequency_document_wise[key][i]>0:\n",
        "                count += 1\n",
        "        if count != 0:\n",
        "            idf[key] = round(math.log(1+(no_of_doc/count),2),2)\n",
        "        else:\n",
        "            idf[key] = 0\n",
        "    return idf\n",
        "\n",
        "def generate_csv(inverse_document_frequency, filename):\n",
        "\n",
        "    with open(f\"{filename}.csv\",\"w\", newline=\"\") as csv_file:\n",
        "        writer = csv.writer(csv_file)\n",
        "        writer.writerow([\"Keywrod\",\"IDF\"])\n",
        "        for key,value in inverse_document_frequency.items():\n",
        "            writer.writerow([key,value])\n",
        "    \n",
        "    df = pd.read_csv(f'{filename}.csv')\n",
        "    print(df)\n",
        "\n",
        "inverse_document_frequency_smooth = generate_idf(word_frequency_document_wise, no_of_doc)\n",
        "generate_csv(inverse_document_frequency, \"idf_frequncy_smooth\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Keywrod   IDF\n",
            "0      abbreviated  6.64\n",
            "1     abbreviation  6.64\n",
            "2              abd  6.64\n",
            "3          abhiyan  6.64\n",
            "4         ablution  6.64\n",
            "...            ...   ...\n",
            "3225         young  5.64\n",
            "3226      youngest  6.64\n",
            "3227          zero  6.64\n",
            "3228          zinc  6.64\n",
            "3229      zirakpur  6.64\n",
            "\n",
            "[3230 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "felAMjt5OTP9",
        "outputId": "6792c995-2fc4-4806-e519-a579496b97e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# effect on idf by using probabilistic inv frequency\n",
        "\n",
        "def generate_idf(word_frequency_document_wise, no_of_doc):\n",
        "\n",
        "    idf = {}\n",
        "    for key in word_frequency_document_wise.keys():\n",
        "        count = 0\n",
        "        for i in range(len(word_frequency_document_wise[key])):\n",
        "            if word_frequency_document_wise[key][i]>0:\n",
        "                count += 1\n",
        "        if count != 0:\n",
        "            try:\n",
        "                idf[key] = round(math.log((no_of_doc-count)/count,2),2)\n",
        "            except:\n",
        "                idf[key] = 0\n",
        "        else:\n",
        "            idf[key] = 0\n",
        "    return idf\n",
        "\n",
        "def generate_csv(inverse_document_frequency, filename):\n",
        "\n",
        "    with open(f\"{filename}.csv\",\"w\", newline=\"\") as csv_file:\n",
        "        writer = csv.writer(csv_file)\n",
        "        writer.writerow([\"Keywrod\",\"IDF\"])\n",
        "        for key,value in inverse_document_frequency.items():\n",
        "            writer.writerow([key,value])\n",
        "    \n",
        "    df = pd.read_csv(f'{filename}.csv')\n",
        "    print(df)\n",
        "\n",
        "inverse_document_frequency_probabilistic = generate_idf(word_frequency_document_wise, no_of_doc)\n",
        "generate_csv(inverse_document_frequency, \"idf_probablistic_smooth\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Keywrod   IDF\n",
            "0      abbreviated  6.64\n",
            "1     abbreviation  6.64\n",
            "2              abd  6.64\n",
            "3          abhiyan  6.64\n",
            "4         ablution  6.64\n",
            "...            ...   ...\n",
            "3225         young  5.64\n",
            "3226      youngest  6.64\n",
            "3227          zero  6.64\n",
            "3228          zinc  6.64\n",
            "3229      zirakpur  6.64\n",
            "\n",
            "[3230 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ach54xrMtoDu",
        "outputId": "ccce2aaf-da28-4ec5-821e-9b97cb49b292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# generation of tf-idf by calculating tf by using log normalization and \n",
        "# idf by using inverse frequency smooth\n",
        "\n",
        "tf_log_idf_inv_freq_smooth_matrix = generate_tf_idf(term_frequency_document_wise,inverse_document_frequency_smooth)\n",
        "write_in_csv(tf_log_idf_inv_freq_smooth_matrix, \"tf_log_idf_inv_freq_smooth\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Keyword   d1   d2   d3   d4   d5  ...  d95  d96  d97  d98  d99  d100\n",
            "0      abbreviated  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "1     abbreviation  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "2              abd  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3          abhiyan  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "4         ablution  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "...            ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...\n",
            "3225         young  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3226      youngest  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3227          zero  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3228          zinc  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3229      zirakpur  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "\n",
            "[3230 rows x 101 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsg3O7NtuAkn",
        "outputId": "a1a14a19-83f2-4bf4-818f-d9ad79eda674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# generation of tf-idf by calculating tf by using log normalization and \n",
        "# idf by using probabilistic inverse frequency\n",
        "\n",
        "tf_log_idf_prob_inv_freq_matrix = generate_tf_idf(term_frequency_document_wise,inverse_document_frequency_probabilistic)\n",
        "write_in_csv(tf_log_idf_prob_inv_freq_matrix, \"tf_log_idf_prob_inv_freq\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Keyword   d1   d2   d3   d4   d5  ...  d95  d96  d97  d98  d99  d100\n",
            "0      abbreviated  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "1     abbreviation  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "2              abd  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3          abhiyan  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "4         ablution  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "...            ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...\n",
            "3225         young  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3226      youngest  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3227          zero  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3228          zinc  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3229      zirakpur  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "\n",
            "[3230 rows x 101 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwq-QZXxrdpT",
        "outputId": "a6a2d588-5e5f-4dd9-edf0-603def0ffa57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# generation of tf-idf by calculating tf by using double normalization and \n",
        "# idf by using inverse frequency smooth\n",
        "\n",
        "tf_normalization_idf_inv_freq_smooth_matrix = generate_tf_idf(term_frequency_document_wise_normalization,inverse_document_frequency_smooth)\n",
        "write_in_csv(tf_normalization_idf_inv_freq_smooth_matrix, \"tf_normalization_idf_inv_freq_smooth\")\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Keyword   d1   d2   d3   d4   d5  ...  d95  d96  d97  d98  d99  d100\n",
            "0      abbreviated  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "1     abbreviation  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "2              abd  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3          abhiyan  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "4         ablution  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "...            ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...\n",
            "3225         young  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3226      youngest  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3227          zero  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3228          zinc  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3229      zirakpur  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "\n",
            "[3230 rows x 101 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTsRFoWGs9Hq",
        "outputId": "ad89118c-f212-4623-8630-60cbb0f1f040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# generation of tf-idf by calculating tf by using double normalization and \n",
        "# idf by using probabilistic inverse frequency\n",
        "\n",
        "tf_normalization_idf_prob_inv_freq_matrix = generate_tf_idf(term_frequency_document_wise_normalization,inverse_document_frequency_probabilistic)\n",
        "write_in_csv(tf_normalization_idf_prob_inv_freq_matrix, \"tf_normalization_idf_prob_inv_freq\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Keyword   d1   d2   d3   d4   d5  ...  d95  d96  d97  d98  d99  d100\n",
            "0      abbreviated  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "1     abbreviation  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "2              abd  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3          abhiyan  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "4         ablution  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "...            ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...\n",
            "3225         young  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3226      youngest  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3227          zero  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3228          zinc  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "3229      zirakpur  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0\n",
            "\n",
            "[3230 rows x 101 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWx2vLfNw8By",
        "outputId": "6f3a4434-9040-42b9-e230-78f636124846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# Question number (c)\n",
        "# representation of document corpus by using VSM model\n",
        "df = pd.read_csv(\"tf_idf.csv\")\n",
        "print(\"VSM model representation\")\n",
        "print(df.transpose())\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VSM model representation\n",
            "                0             1    2     ...  3227  3228      3229\n",
            "Keyword  abbreviated  abbreviation  abd  ...  zero  zinc  zirakpur\n",
            "d1                 0             0    0  ...     0     0         0\n",
            "d2                 0             0    0  ...     0     0         0\n",
            "d3                 0             0    0  ...     0     0         0\n",
            "d4                 0             0    0  ...     0     0         0\n",
            "...              ...           ...  ...  ...   ...   ...       ...\n",
            "d96                0             0    0  ...     0     0         0\n",
            "d97                0             0    0  ...     0     0         0\n",
            "d98                0             0    0  ...     0     0         0\n",
            "d99                0             0    0  ...     0     0         0\n",
            "d100               0             0    0  ...     0     0         0\n",
            "\n",
            "[101 rows x 3230 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAhdJKHm5zIZ",
        "outputId": "069d2f72-4515-417f-fbba-db0945612e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# query representation and ranked list\n",
        "from scipy import spatial\n",
        "\n",
        "def calculate_tf_idf(keyword):\n",
        "\n",
        "    return inverse_document_frequency[keyword]\n",
        "\n",
        "def sort_acc_to_value(x):\n",
        "    return x[0]\n",
        "\n",
        "def generate_ranked_list(weight_dict_query, weight_dict_corpus):\n",
        "\n",
        "    ranked_list_query = defaultdict(list)\n",
        "    for key, value in weight_dict_query.items():\n",
        "        for i in range(0, len(weight_dict_corpus[key])):\n",
        "            temp = spatial.distance.cosine(value, weight_dict_corpus[key][i])\n",
        "            ranked_list_query[key].append( (round(temp,3), i) )\n",
        "\n",
        "    for key, value in ranked_list_query.items():\n",
        "        value.sort(key = sort_acc_to_value, reverse = True)\n",
        "        print(key,\":\", value)\n",
        "\n",
        "    print()\n",
        "\n",
        "\n",
        "def processQuery(querys, tf_idf_matrix):\n",
        "    \n",
        "    weight_dict_query = defaultdict(list)\n",
        "    weight_dict_corpus = defaultdict(list)\n",
        "    for query in querys:\n",
        "        query_array = query.split(\" \")\n",
        "        for keyword in query_array:\n",
        "            weight_dict_query[query].append(calculate_tf_idf(keyword))   \n",
        "    for query in querys:\n",
        "        query_array = query.split()\n",
        "\n",
        "        for i in range(0, no_of_doc):\n",
        "            temp = []\n",
        "            for keyword in query_array:\n",
        "                temp.append(tf_idf_matrix[keyword][i])            \n",
        "            weight_dict_corpus[query].append(temp)\n",
        "    return (weight_dict_query, weight_dict_corpus)\n",
        "\n",
        "query_2_words = [\"indian city\", \"uttar pradesh\", \"state city\"]\n",
        "weight_dict_query, weight_dict_corpus = processQuery(query_2_words, tf_idf_matrix)\n",
        "generate_ranked_list(weight_dict_query, weight_dict_corpus)\n",
        "\n",
        "query_3_words = [\"indian city temple\", \"uttar pradesh people\", \"state city country\"]\n",
        "weight_dict_query, weight_dict_corpus = processQuery(query_3_words, tf_idf_matrix)\n",
        "generate_ranked_list(weight_dict_query, weight_dict_corpus)\n",
        "\n",
        "query_5_words = [\"indian city state current population\", \"uttar pradesh hindu heritage holy\", \"state capital city world population\"]\n",
        "weight_dict_query, weight_dict_corpus = processQuery(query_5_words, tf_idf_matrix)\n",
        "generate_ranked_list(weight_dict_query, weight_dict_corpus)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "indian city : [(0.925, 2), (0.925, 3), (0.925, 5), (0.925, 13), (0.925, 14), (0.925, 16), (0.925, 32), (0.925, 34), (0.925, 39), (0.925, 43), (0.925, 56), (0.925, 61), (0.925, 62), (0.034, 6), (0.034, 36), (0.029, 12), (0.023, 19), (0.019, 25), (0.019, 44), (0.019, 49), (0.014, 7), (0.014, 17), (0.014, 38), (0.014, 40), (0.011, 27), (0.007, 0), (0.007, 18), (0.007, 20), (0.007, 37), (0.007, 46), (0.007, 48), (0.006, 28), (0.004, 15), (0.003, 8), (0.003, 10), (0.003, 22), (0.003, 23), (0.003, 33), (0.003, 42), (0.003, 45), (0.002, 4), (0.002, 21), (0.002, 26), (0.002, 31), (0.001, 41), (0.0, 1), (0.0, 9), (0.0, 11), (0.0, 24), (0.0, 29), (0.0, 30), (0.0, 35), (0.0, 47), (nan, 63), (0.925, 65), (nan, 67), (0.925, 71), (0.925, 75), (0.925, 77), (0.925, 82), (0.925, 86), (0.925, 94), (0.925, 97), (0.925, 99), (0.034, 73), (0.029, 72), (0.029, 98), (0.023, 87), (0.023, 93), (0.019, 53), (0.019, 76), (0.019, 79), (0.019, 81), (0.019, 84), (0.019, 90), (0.019, 92), (0.014, 60), (0.014, 88), (0.011, 51), (0.011, 55), (0.007, 96), (0.004, 69), (0.003, 50), (0.003, 54), (0.003, 59), (0.003, 78), (0.002, 64), (0.002, 74), (0.002, 89), (0.001, 68), (0.001, 80), (0.001, 83), (0.001, 85), (0.001, 95), (0.0, 52), (0.0, 57), (0.0, 58), (0.0, 66), (0.0, 70), (0.0, 91)]\n",
            "uttar pradesh : [(0.436, 0), (nan, 2), (0.436, 4), (0.436, 5), (nan, 6), (nan, 7), (nan, 8), (nan, 9), (nan, 10), (nan, 11), (nan, 12), (nan, 14), (0.436, 15), (0.0, 13), (nan, 16), (nan, 18), (nan, 19), (nan, 20), (0.436, 21), (0.0, 1), (0.0, 3), (0.0, 17), (nan, 22), (nan, 23), (nan, 24), (nan, 26), (0.0, 27), (0.0, 28), (nan, 29), (nan, 30), (0.436, 31), (nan, 32), (nan, 33), (nan, 34), (nan, 35), (nan, 36), (0.436, 37), (0.0, 25), (nan, 38), (nan, 39), (nan, 40), (nan, 41), (nan, 42), (nan, 43), (nan, 44), (0.436, 49), (0.174, 47), (0.0, 45), (0.0, 46), (0.0, 48), (nan, 51), (nan, 52), (nan, 53), (0.436, 54), (nan, 57), (0.436, 58), (0.174, 56), (0.0, 50), (nan, 59), (nan, 60), (nan, 61), (nan, 62), (nan, 63), (nan, 64), (nan, 65), (0.436, 66), (0.002, 55), (nan, 67), (nan, 68), (nan, 69), (nan, 70), (nan, 71), (nan, 72), (nan, 73), (0.436, 75), (0.0, 74), (nan, 76), (nan, 77), (nan, 78), (nan, 79), (nan, 80), (nan, 81), (nan, 82), (nan, 83), (0.436, 85), (0.0, 84), (0.0, 86), (nan, 87), (nan, 88), (0.436, 89), (nan, 90), (nan, 91), (0.0, 92), (nan, 93), (nan, 94), (0.436, 95), (nan, 96), (0.0, 97), (nan, 98), (nan, 99)]\n",
            "state city : [(0.757, 3), (0.757, 14), (0.757, 20), (0.757, 38), (0.184, 6), (0.184, 11), (0.184, 36), (0.143, 32), (0.121, 25), (0.121, 29), (0.099, 7), (0.099, 47), (0.058, 5), (0.058, 46), (0.058, 48), (0.04, 31), (0.031, 43), (0.024, 2), (0.024, 8), (0.024, 13), (0.024, 19), (0.024, 23), (0.024, 33), (0.024, 42), (0.024, 45), (0.017, 1), (0.017, 21), (0.017, 49), (0.011, 24), (0.011, 41), (0.007, 30), (0.006, 9), (0.006, 34), (0.005, 4), (0.005, 12), (0.005, 44), (0.003, 18), (0.003, 22), (0.003, 37), (0.003, 39), (0.002, 15), (0.002, 17), (0.002, 28), (0.002, 40), (0.001, 26), (0.0, 0), (0.0, 10), (0.0, 16), (0.0, 27), (0.0, 35), (nan, 63), (nan, 67), (0.757, 86), (0.757, 88), (0.164, 69), (0.164, 72), (0.143, 50), (0.143, 57), (0.121, 64), (0.121, 79), (0.121, 89), (0.078, 62), (0.078, 83), (0.058, 96), (0.024, 59), (0.024, 93), (0.024, 99), (0.017, 53), (0.017, 74), (0.017, 84), (0.017, 90), (0.017, 92), (0.017, 97), (0.016, 80), (0.011, 56), (0.011, 82), (0.007, 77), (0.006, 51), (0.006, 55), (0.006, 85), (0.005, 76), (0.004, 52), (0.003, 87), (0.002, 60), (0.002, 68), (0.002, 73), (0.002, 91), (0.002, 95), (0.002, 98), (0.001, 54), (0.001, 58), (0.001, 65), (0.001, 70), (0.0, 61), (0.0, 66), (0.0, 71), (0.0, 75), (0.0, 78), (0.0, 81), (0.0, 94)]\n",
            "\n",
            "indian city temple : [(0.986, 2), (0.986, 3), (0.986, 5), (0.986, 13), (0.986, 14), (0.986, 16), (0.986, 32), (0.986, 34), (0.986, 39), (0.986, 43), (0.986, 56), (0.986, 61), (0.986, 62), (0.82, 6), (0.82, 36), (0.819, 12), (0.818, 25), (0.818, 49), (0.817, 7), (0.817, 17), (0.817, 38), (0.816, 27), (0.815, 0), (0.815, 8), (0.815, 10), (0.815, 15), (0.815, 18), (0.815, 20), (0.815, 23), (0.815, 28), (0.815, 33), (0.815, 37), (0.815, 42), (0.815, 46), (0.814, 1), (0.814, 4), (0.814, 9), (0.814, 11), (0.814, 24), (0.814, 29), (0.814, 30), (0.814, 31), (0.814, 35), (0.814, 41), (0.814, 47), (0.016, 26), (0.009, 19), (0.004, 45), (0.004, 48), (0.001, 40), (0.001, 44), (0.0, 21), (0.0, 22), (nan, 63), (0.986, 65), (nan, 67), (0.986, 71), (0.986, 75), (0.986, 77), (0.986, 82), (0.986, 86), (0.986, 94), (0.986, 97), (0.986, 99), (0.818, 76), (0.818, 79), (0.818, 84), (0.818, 87), (0.818, 90), (0.818, 93), (0.816, 55), (0.815, 54), (0.815, 59), (0.815, 96), (0.814, 57), (0.814, 58), (0.814, 64), (0.814, 66), (0.814, 68), (0.814, 70), (0.814, 74), (0.814, 80), (0.814, 83), (0.814, 85), (0.814, 95), (0.094, 52), (0.07, 91), (0.016, 69), (0.016, 89), (0.008, 53), (0.004, 88), (0.004, 98), (0.003, 50), (0.001, 60), (0.001, 72), (0.001, 73), (0.001, 81), (0.001, 92), (0.0, 51), (0.0, 78)]\n",
            "uttar pradesh people : [(0.619, 0), (nan, 2), (0.619, 4), (0.619, 5), (0.325, 1), (0.325, 3), (nan, 7), (nan, 8), (nan, 9), (nan, 10), (nan, 11), (nan, 12), (nan, 14), (nan, 16), (nan, 19), (0.619, 21), (0.325, 13), (0.325, 17), (0.262, 6), (0.262, 18), (0.262, 20), (0.213, 15), (nan, 22), (nan, 23), (nan, 24), (0.325, 28), (0.262, 26), (0.0, 27), (nan, 29), (nan, 30), (0.619, 31), (nan, 32), (nan, 33), (nan, 34), (nan, 35), (nan, 36), (0.619, 37), (0.325, 25), (nan, 38), (nan, 39), (nan, 40), (nan, 41), (nan, 42), (nan, 43), (nan, 44), (0.619, 49), (0.443, 47), (0.325, 45), (0.325, 46), (0.0, 48), (nan, 51), (nan, 52), (0.619, 54), (0.262, 53), (nan, 57), (0.619, 58), (0.443, 56), (0.325, 50), (nan, 59), (nan, 60), (nan, 61), (nan, 62), (nan, 63), (nan, 64), (nan, 65), (0.619, 66), (0.327, 55), (nan, 67), (nan, 68), (nan, 70), (nan, 71), (nan, 72), (nan, 73), (0.619, 75), (0.325, 74), (nan, 76), (nan, 77), (nan, 78), (nan, 79), (nan, 81), (nan, 83), (0.619, 85), (0.325, 84), (0.325, 86), (0.262, 80), (0.262, 82), (nan, 87), (nan, 88), (0.619, 89), (nan, 90), (nan, 91), (0.325, 92), (0.262, 69), (nan, 93), (nan, 94), (0.619, 95), (nan, 96), (0.325, 97), (nan, 98), (nan, 99)]\n",
            "state city country : [(0.99, 3), (0.99, 14), (0.99, 20), (0.99, 38), (0.966, 6), (0.966, 11), (0.966, 36), (0.964, 32), (0.963, 25), (0.963, 29), (0.962, 7), (0.962, 47), (0.96, 5), (0.96, 31), (0.96, 46), (0.96, 48), (0.959, 1), (0.959, 2), (0.959, 8), (0.959, 13), (0.959, 19), (0.959, 21), (0.959, 23), (0.959, 33), (0.959, 42), (0.959, 45), (0.958, 0), (0.958, 4), (0.958, 9), (0.958, 10), (0.958, 15), (0.958, 16), (0.958, 17), (0.958, 18), (0.958, 22), (0.958, 24), (0.958, 26), (0.958, 27), (0.958, 30), (0.958, 34), (0.958, 35), (0.958, 37), (0.958, 39), (0.958, 40), (0.958, 41), (0.958, 44), (0.007, 28), (0.004, 12), (0.001, 43), (0.001, 49), (nan, 63), (nan, 67), (0.99, 86), (0.99, 88), (0.965, 69), (0.965, 72), (0.964, 50), (0.964, 57), (0.963, 79), (0.963, 89), (0.961, 83), (0.96, 96), (0.959, 53), (0.959, 59), (0.959, 74), (0.959, 84), (0.959, 90), (0.959, 92), (0.959, 93), (0.959, 97), (0.959, 99), (0.958, 51), (0.958, 52), (0.958, 54), (0.958, 55), (0.958, 56), (0.958, 61), (0.958, 65), (0.958, 66), (0.958, 68), (0.958, 70), (0.958, 71), (0.958, 75), (0.958, 76), (0.958, 77), (0.958, 78), (0.958, 82), (0.958, 91), (0.958, 94), (0.958, 95), (0.958, 98), (0.006, 73), (0.005, 81), (0.005, 85), (0.004, 58), (0.004, 87), (0.003, 80), (0.002, 60), (0.0, 62), (0.0, 64)]\n",
            "\n",
            "indian city state current population : [(0.994, 3), (0.978, 32), (0.976, 5), (0.976, 62), (0.975, 2), (0.975, 13), (0.975, 34), (0.975, 43), (0.974, 16), (0.922, 22), (0.92, 17), (0.918, 38), (0.917, 19), (0.917, 20), (0.915, 29), (0.914, 1), (0.914, 4), (0.914, 7), (0.914, 26), (0.914, 31), (0.914, 41), (0.914, 46), (0.914, 48), (0.913, 8), (0.913, 9), (0.913, 23), (0.913, 33), (0.913, 35), (0.746, 47), (0.742, 28), (0.741, 14), (0.737, 24), (0.732, 6), (0.732, 12), (0.731, 11), (0.731, 27), (0.73, 0), (0.73, 30), (0.73, 40), (0.728, 10), (0.728, 18), (0.728, 36), (0.728, 37), (0.728, 49), (0.727, 21), (0.727, 25), (0.727, 42), (0.727, 45), (0.04, 15), (0.038, 39), (0.001, 44), (nan, 63), (nan, 67), (0.994, 86), (0.975, 77), (0.975, 99), (0.974, 65), (0.974, 71), (0.974, 75), (0.924, 81), (0.92, 76), (0.919, 54), (0.918, 88), (0.917, 84), (0.917, 92), (0.917, 93), (0.916, 51), (0.916, 55), (0.916, 78), (0.915, 57), (0.915, 79), (0.914, 68), (0.914, 83), (0.914, 96), (0.913, 58), (0.913, 59), (0.913, 70), (0.913, 74), (0.913, 95), (0.756, 66), (0.746, 61), (0.745, 56), (0.74, 82), (0.74, 94), (0.74, 97), (0.736, 89), (0.735, 52), (0.733, 98), (0.732, 87), (0.731, 53), (0.731, 73), (0.731, 85), (0.731, 91), (0.73, 60), (0.728, 64), (0.728, 90), (0.727, 69), (0.727, 72), (0.727, 80), (0.004, 50)]\n",
            "uttar pradesh hindu heritage holy : [(0.744, 0), (nan, 2), (0.744, 5), (0.601, 6), (nan, 7), (nan, 8), (nan, 9), (nan, 11), (nan, 12), (nan, 14), (nan, 18), (0.601, 19), (0.573, 16), (0.547, 1), (0.547, 13), (0.526, 4), (0.392, 15), (nan, 20), (0.553, 21), (0.547, 17), (0.189, 3), (nan, 22), (nan, 23), (nan, 24), (nan, 26), (0.547, 27), (0.17, 28), (nan, 29), (nan, 30), (0.744, 31), (0.601, 10), (nan, 32), (nan, 33), (nan, 34), (nan, 35), (nan, 36), (0.744, 37), (0.547, 25), (nan, 38), (nan, 39), (nan, 40), (nan, 41), (nan, 42), (nan, 43), (0.744, 49), (0.573, 44), (0.547, 48), (0.389, 46), (0.246, 47), (0.048, 45), (nan, 51), (nan, 52), (0.744, 54), (nan, 57), (0.744, 58), (nan, 59), (nan, 62), (nan, 64), (nan, 65), (0.744, 66), (nan, 67), (nan, 68), (nan, 69), (nan, 70), (nan, 71), (nan, 72), (0.744, 75), (nan, 76), (nan, 77), (nan, 78), (nan, 79), (0.601, 81), (nan, 82), (nan, 83), (0.744, 85), (0.601, 61), (0.601, 63), (0.601, 88), (0.573, 60), (0.573, 73), (0.573, 80), (0.573, 87), (0.553, 89), (0.548, 55), (nan, 90), (0.601, 91), (0.547, 84), (0.547, 86), (0.547, 92), (0.459, 56), (0.428, 74), (0.416, 53), (0.277, 50), (nan, 93), (nan, 94), (0.744, 95), (0.573, 96), (0.442, 97), (nan, 98), (0.573, 99)]\n",
            "state capital city world population : [(0.987, 3), (0.956, 32), (0.953, 7), (0.952, 62), (0.951, 5), (0.951, 48), (0.95, 23), (0.95, 33), (0.95, 59), (0.949, 41), (0.949, 51), (0.843, 26), (0.835, 31), (0.835, 38), (0.834, 20), (0.834, 43), (0.832, 9), (0.832, 34), (0.831, 35), (0.826, 2), (0.826, 8), (0.826, 13), (0.826, 17), (0.826, 19), (0.825, 16), (0.825, 39), (0.49, 36), (0.489, 47), (0.479, 14), (0.478, 37), (0.476, 42), (0.472, 44), (0.471, 0), (0.469, 10), (0.46, 12), (0.456, 21), (0.456, 30), (0.456, 40), (0.455, 24), (0.452, 18), (0.45, 45), (0.197, 46), (0.168, 4), (0.166, 22), (0.151, 15), (0.148, 29), (0.147, 1), (0.05, 28), (0.015, 11), (0.003, 27), (0.002, 49), (0.001, 6), (0.001, 25), (nan, 63), (nan, 67), (0.95, 93), (0.949, 84), (0.948, 75), (0.843, 58), (0.838, 76), (0.837, 54), (0.837, 70), (0.835, 88), (0.834, 86), (0.832, 55), (0.829, 71), (0.827, 57), (0.826, 65), (0.826, 68), (0.826, 81), (0.826, 92), (0.826, 96), (0.825, 77), (0.505, 94), (0.494, 66), (0.477, 64), (0.476, 97), (0.476, 98), (0.472, 60), (0.46, 56), (0.459, 91), (0.457, 69), (0.456, 82), (0.453, 52), (0.451, 53), (0.451, 72), (0.451, 89), (0.164, 79), (0.164, 83), (0.163, 74), (0.163, 99), (0.148, 78), (0.147, 95), (0.095, 73), (0.05, 87), (0.019, 61), (0.013, 85), (0.005, 80), (0.002, 90), (0.001, 50)]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHMbPMVpG2fY",
        "outputId": "4979bdce-2cce-49b8-c696-83e02c5abe82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# Question number (d)\n",
        "# by using tf-idfs (tf => double normalization, idf => probabilistic inverse frequency) \n",
        "query_2_words = [\"indian city\", \"uttar pradesh\", \"state city\"]\n",
        "weight_dict_query, weight_dict_corpus = processQuery(query_2_words, tf_normalization_idf_prob_inv_freq_matrix)\n",
        "generate_ranked_list(weight_dict_query, weight_dict_corpus)\n",
        "\n",
        "query_3_words = [\"indian city temple\", \"uttar pradesh people\", \"state city country\"]\n",
        "weight_dict_query, weight_dict_corpus = processQuery(query_3_words, tf_normalization_idf_prob_inv_freq_matrix)\n",
        "generate_ranked_list(weight_dict_query, weight_dict_corpus)\n",
        "\n",
        "query_5_words = [\"indian city state current population\", \"uttar pradesh hindu heritage holy\", \"state capital city world population\"]\n",
        "weight_dict_query, weight_dict_corpus = processQuery(query_5_words, tf_normalization_idf_prob_inv_freq_matrix)\n",
        "generate_ranked_list(weight_dict_query, weight_dict_corpus)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "indian city : [(1.481, 24), (1.392, 41), (1.377, 35), (1.374, 9), (1.371, 1), (1.369, 30), (1.367, 57), (1.355, 59), (nan, 63), (nan, 67), (1.377, 70), (1.362, 47), (1.359, 66), (1.358, 52), (1.355, 8), (1.355, 10), (1.355, 22), (1.355, 23), (1.355, 33), (1.355, 42), (1.355, 45), (1.355, 54), (1.355, 78), (1.35, 83), (1.342, 0), (1.342, 18), (1.342, 20), (1.342, 37), (1.342, 46), (1.342, 48), (1.342, 96), (1.341, 91), (1.34, 29), (1.34, 58), (1.338, 68), (1.33, 27), (1.33, 51), (1.33, 55), (1.328, 64), (1.328, 74), (1.328, 89), (1.324, 11), (1.319, 7), (1.319, 17), (1.319, 38), (1.319, 40), (1.319, 60), (1.319, 88), (1.318, 4), (1.318, 21), (1.318, 26), (1.316, 80), (1.309, 25), (1.309, 44), (1.309, 84), (1.309, 90), (1.309, 92), (1.308, 50), (1.303, 15), (1.301, 95), (1.3, 49), (1.3, 53), (1.3, 76), (1.3, 79), (1.3, 81), (1.296, 85), (1.295, 69), (1.292, 31), (1.291, 19), (1.291, 87), (1.291, 93), (1.278, 12), (1.271, 72), (1.271, 98), (1.264, 6), (1.258, 36), (1.258, 73), (1.25, 28), (1.075, 2), (1.075, 3), (1.075, 5), (1.075, 13), (1.075, 14), (1.075, 16), (1.075, 32), (1.075, 34), (1.075, 39), (1.075, 43), (1.075, 56), (1.075, 61), (1.075, 62), (1.075, 65), (1.075, 71), (1.075, 75), (1.075, 77), (1.075, 82), (1.075, 86), (1.075, 94), (1.075, 97), (1.075, 99)]\n",
            "uttar pradesh : [(0.436, 0), (nan, 2), (0.436, 4), (0.436, 5), (nan, 6), (nan, 7), (nan, 8), (nan, 9), (nan, 10), (nan, 11), (nan, 12), (nan, 14), (0.436, 15), (0.013, 13), (nan, 16), (nan, 18), (nan, 19), (nan, 20), (0.436, 21), (0.013, 17), (nan, 22), (nan, 23), (nan, 24), (nan, 26), (0.022, 28), (0.013, 3), (0.013, 27), (nan, 29), (nan, 30), (0.436, 31), (nan, 32), (nan, 33), (nan, 34), (nan, 35), (nan, 36), (0.436, 37), (0.025, 25), (0.013, 1), (nan, 38), (nan, 39), (nan, 40), (nan, 41), (nan, 42), (nan, 43), (nan, 44), (0.436, 49), (0.174, 47), (0.025, 46), (0.018, 45), (0.013, 48), (nan, 51), (nan, 52), (nan, 53), (0.436, 54), (nan, 57), (0.436, 58), (0.174, 56), (nan, 59), (nan, 60), (nan, 61), (nan, 62), (nan, 63), (nan, 64), (nan, 65), (0.436, 66), (0.032, 55), (nan, 67), (nan, 68), (nan, 69), (nan, 70), (nan, 71), (nan, 72), (nan, 73), (0.436, 75), (0.022, 74), (0.013, 50), (nan, 76), (nan, 77), (nan, 78), (nan, 79), (nan, 80), (nan, 81), (nan, 82), (nan, 83), (0.436, 85), (0.025, 84), (0.013, 86), (nan, 87), (nan, 88), (0.436, 89), (nan, 90), (nan, 91), (0.018, 92), (nan, 93), (nan, 94), (0.436, 95), (nan, 96), (0.022, 97), (nan, 98), (nan, 99)]\n",
            "state city : [(1.825, 22), (1.82, 61), (nan, 63), (nan, 67), (1.82, 75), (1.81, 41), (1.81, 82), (1.795, 27), (1.794, 54), (1.794, 70), (1.781, 66), (1.781, 81), (1.779, 30), (1.779, 77), (1.778, 0), (1.763, 65), (1.762, 10), (1.762, 35), (1.762, 78), (1.76, 15), (1.754, 26), (1.754, 58), (1.748, 17), (1.748, 40), (1.748, 60), (1.748, 68), (1.746, 18), (1.746, 37), (1.746, 39), (1.745, 16), (1.745, 71), (1.745, 94), (1.741, 87), (1.738, 73), (1.736, 91), (1.736, 98), (1.735, 44), (1.73, 9), (1.73, 34), (1.73, 51), (1.73, 55), (1.727, 2), (1.727, 8), (1.727, 13), (1.727, 23), (1.727, 33), (1.727, 42), (1.727, 45), (1.727, 59), (1.727, 95), (1.721, 4), (1.721, 12), (1.721, 28), (1.721, 76), (1.716, 24), (1.714, 52), (1.711, 5), (1.711, 46), (1.711, 48), (1.711, 96), (1.702, 1), (1.702, 74), (1.702, 84), (1.702, 90), (1.702, 92), (1.702, 97), (1.695, 62), (1.695, 83), (1.689, 21), (1.689, 49), (1.689, 53), (1.68, 7), (1.68, 47), (1.676, 19), (1.676, 93), (1.676, 99), (1.674, 85), (1.667, 25), (1.667, 56), (1.667, 64), (1.667, 89), (1.665, 80), (1.654, 29), (1.654, 79), (1.644, 43), (1.641, 32), (1.641, 50), (1.641, 57), (1.623, 31), (1.622, 69), (1.611, 72), (1.6, 6), (1.59, 11), (1.59, 36), (1.243, 3), (1.243, 14), (1.243, 20), (1.243, 38), (1.243, 86), (1.243, 88)]\n",
            "\n",
            "indian city temple : [(1.089, 24), (1.073, 41), (1.07, 9), (1.07, 35), (1.069, 1), (1.069, 30), (1.068, 57), (1.067, 47), (1.066, 8), (1.066, 10), (1.066, 23), (1.066, 33), (1.066, 42), (1.066, 59), (1.064, 0), (1.064, 18), (1.064, 20), (1.064, 37), (1.064, 46), (1.063, 29), (1.061, 27), (1.06, 11), (1.059, 4), (1.059, 7), (1.059, 17), (1.059, 38), (1.057, 25), (1.056, 15), (1.056, 49), (1.054, 31), (1.052, 12), (1.049, 6), (1.048, 36), (1.047, 28), (1.014, 2), (1.014, 3), (1.014, 5), (1.014, 13), (1.014, 14), (1.014, 16), (1.014, 32), (1.014, 34), (1.014, 39), (1.014, 43), (0.823, 26), (0.811, 44), (0.803, 40), (0.788, 21), (0.773, 22), (0.744, 48), (0.732, 45), (0.678, 19), (nan, 63), (nan, 67), (1.07, 70), (1.067, 66), (1.066, 54), (1.065, 83), (1.064, 96), (1.063, 58), (1.063, 68), (1.061, 55), (1.061, 64), (1.061, 74), (1.059, 80), (1.057, 84), (1.057, 90), (1.056, 76), (1.056, 79), (1.056, 95), (1.055, 85), (1.054, 87), (1.054, 93), (1.014, 56), (1.014, 61), (1.014, 62), (1.014, 65), (1.014, 71), (1.014, 75), (1.014, 77), (1.014, 82), (1.014, 86), (1.014, 94), (1.014, 97), (1.014, 99), (0.876, 52), (0.859, 91), (0.853, 73), (0.843, 72), (0.84, 69), (0.818, 81), (0.815, 89), (0.811, 92), (0.811, 98), (0.803, 60), (0.794, 51), (0.773, 78), (0.765, 88), (0.726, 53), (0.709, 50)]\n",
            "uttar pradesh people : [(0.619, 0), (nan, 2), (0.619, 4), (0.619, 5), (0.334, 1), (0.334, 3), (nan, 7), (nan, 8), (nan, 9), (nan, 10), (nan, 11), (nan, 12), (nan, 14), (nan, 16), (nan, 19), (0.619, 21), (0.334, 13), (0.262, 6), (0.262, 18), (0.262, 20), (0.196, 15), (nan, 22), (nan, 23), (nan, 24), (0.34, 28), (0.334, 17), (0.262, 26), (0.047, 27), (nan, 29), (nan, 30), (0.619, 31), (nan, 32), (nan, 33), (nan, 34), (nan, 35), (nan, 36), (0.619, 37), (0.342, 25), (nan, 38), (nan, 39), (nan, 40), (nan, 41), (nan, 42), (nan, 43), (nan, 44), (0.619, 49), (0.443, 47), (0.342, 46), (0.338, 45), (0.047, 48), (nan, 51), (nan, 52), (0.619, 54), (0.262, 53), (nan, 57), (0.619, 58), (0.443, 56), (0.334, 50), (nan, 59), (nan, 60), (nan, 61), (nan, 62), (nan, 63), (nan, 64), (nan, 65), (0.619, 66), (0.347, 55), (nan, 67), (nan, 68), (nan, 70), (nan, 71), (nan, 72), (nan, 73), (0.619, 75), (0.34, 74), (nan, 76), (nan, 77), (nan, 78), (nan, 79), (nan, 81), (nan, 83), (0.619, 85), (0.342, 84), (0.334, 86), (0.262, 80), (0.262, 82), (nan, 87), (nan, 88), (0.619, 89), (nan, 90), (nan, 91), (0.338, 92), (0.262, 69), (nan, 93), (nan, 94), (0.619, 95), (nan, 96), (0.34, 97), (nan, 98), (nan, 99)]\n",
            "state city country : [(1.035, 22), (1.034, 41), (1.034, 61), (nan, 63), (nan, 67), (1.034, 75), (1.034, 82), (1.033, 0), (1.033, 27), (1.033, 30), (1.033, 54), (1.033, 66), (1.033, 70), (1.033, 77), (1.032, 10), (1.032, 15), (1.032, 26), (1.032, 35), (1.032, 65), (1.032, 78), (1.031, 2), (1.031, 8), (1.031, 9), (1.031, 13), (1.031, 16), (1.031, 17), (1.031, 18), (1.031, 23), (1.031, 33), (1.031, 34), (1.031, 37), (1.031, 39), (1.031, 40), (1.031, 42), (1.031, 44), (1.031, 45), (1.031, 51), (1.031, 55), (1.031, 59), (1.031, 68), (1.031, 71), (1.031, 91), (1.031, 94), (1.031, 95), (1.031, 98), (1.03, 1), (1.03, 4), (1.03, 5), (1.03, 24), (1.03, 46), (1.03, 48), (1.03, 52), (1.03, 74), (1.03, 76), (1.03, 84), (1.03, 90), (1.03, 92), (1.03, 96), (1.03, 97), (1.029, 7), (1.029, 21), (1.029, 47), (1.029, 53), (1.029, 83), (1.028, 19), (1.028, 25), (1.028, 56), (1.028, 89), (1.028, 93), (1.028, 99), (1.027, 29), (1.027, 32), (1.027, 50), (1.027, 57), (1.027, 79), (1.026, 31), (1.026, 69), (1.026, 72), (1.025, 6), (1.025, 11), (1.025, 36), (1.01, 3), (1.01, 14), (1.01, 20), (1.01, 38), (1.01, 86), (1.01, 88), (0.646, 28), (0.632, 85), (0.609, 73), (0.572, 80), (0.563, 12), (0.553, 43), (0.549, 81), (0.547, 87), (0.537, 58), (0.511, 49), (0.501, 60), (0.487, 64), (0.461, 62)]\n",
            "\n",
            "indian city state current population : [(1.041, 41), (1.04, 9), (1.04, 35), (1.039, 1), (1.039, 22), (1.038, 8), (1.038, 23), (1.038, 33), (1.038, 57), (1.038, 59), (1.037, 46), (1.037, 48), (1.036, 4), (1.036, 17), (1.036, 26), (1.036, 29), (1.035, 7), (1.033, 19), (1.032, 31), (1.028, 20), (1.027, 24), (1.027, 38), (1.021, 47), (1.02, 0), (1.02, 28), (1.019, 2), (1.019, 10), (1.019, 12), (1.019, 13), (1.019, 16), (1.019, 18), (1.019, 34), (1.019, 37), (1.019, 42), (1.019, 45), (1.018, 5), (1.018, 11), (1.018, 49), (1.017, 25), (1.017, 43), (1.016, 21), (1.016, 30), (1.016, 32), (1.016, 40), (1.015, 36), (1.013, 27), (1.01, 6), (1.006, 3), (0.985, 14), (0.399, 15), (0.339, 44), (0.288, 39), (nan, 63), (nan, 67), (1.04, 70), (1.039, 54), (1.038, 78), (1.038, 83), (1.037, 58), (1.037, 68), (1.037, 96), (1.036, 51), (1.036, 55), (1.036, 74), (1.035, 81), (1.035, 84), (1.035, 92), (1.034, 76), (1.034, 95), (1.033, 79), (1.033, 93), (1.027, 88), (1.024, 66), (1.023, 52), (1.021, 75), (1.021, 91), (1.02, 65), (1.02, 77), (1.019, 60), (1.019, 71), (1.019, 85), (1.019, 87), (1.019, 89), (1.019, 98), (1.018, 62), (1.018, 90), (1.017, 99), (1.016, 72), (1.016, 73), (1.014, 69), (1.013, 80), (1.012, 64), (1.011, 53), (1.006, 86), (1.005, 61), (1.004, 56), (0.998, 94), (0.997, 82), (0.994, 97), (0.344, 50)]\n",
            "uttar pradesh hindu heritage holy : [(0.744, 0), (nan, 2), (0.744, 5), (0.601, 6), (nan, 7), (nan, 8), (nan, 9), (nan, 11), (nan, 12), (nan, 14), (nan, 18), (0.601, 19), (0.573, 16), (0.553, 1), (0.553, 13), (0.553, 17), (0.53, 4), (nan, 20), (0.509, 21), (0.373, 15), (0.219, 3), (nan, 22), (nan, 23), (nan, 24), (nan, 26), (0.553, 27), (0.121, 28), (nan, 29), (nan, 30), (0.744, 31), (0.601, 10), (nan, 32), (nan, 33), (nan, 34), (nan, 35), (nan, 36), (0.744, 37), (0.558, 25), (nan, 38), (nan, 39), (nan, 40), (nan, 41), (nan, 42), (nan, 43), (0.744, 49), (0.573, 44), (0.553, 48), (0.387, 46), (0.153, 47), (0.028, 45), (nan, 51), (nan, 52), (0.744, 54), (nan, 57), (0.744, 58), (nan, 59), (nan, 62), (nan, 64), (nan, 65), (0.744, 66), (nan, 67), (nan, 68), (nan, 69), (nan, 70), (nan, 71), (nan, 72), (0.744, 75), (nan, 76), (nan, 77), (nan, 78), (nan, 79), (0.601, 81), (nan, 82), (nan, 83), (0.744, 85), (0.601, 61), (0.601, 63), (0.601, 88), (0.573, 60), (0.573, 73), (0.573, 80), (0.573, 87), (0.562, 55), (0.558, 84), (0.553, 86), (0.528, 89), (0.449, 56), (0.385, 74), (nan, 90), (0.601, 91), (0.555, 92), (0.432, 53), (0.123, 50), (nan, 93), (nan, 94), (0.744, 95), (0.573, 96), (0.412, 97), (nan, 98), (0.573, 99)]\n",
            "state capital city world population : [(1.079, 16), (1.079, 39), (1.077, 2), (1.077, 8), (1.077, 13), (1.077, 35), (1.076, 17), (1.073, 9), (1.073, 34), (1.07, 19), (1.07, 26), (1.063, 43), (1.06, 31), (1.057, 20), (1.053, 38), (1.044, 0), (1.043, 10), (1.043, 47), (1.042, 41), (1.041, 24), (1.041, 44), (1.038, 18), (1.038, 23), (1.038, 33), (1.037, 5), (1.037, 12), (1.037, 36), (1.037, 45), (1.037, 48), (1.035, 7), (1.033, 32), (1.032, 30), (1.032, 40), (1.029, 21), (1.013, 3), (1.001, 37), (0.997, 42), (0.969, 14), (0.932, 28), (0.921, 15), (0.909, 22), (0.904, 29), (0.903, 46), (0.88, 4), (0.877, 49), (0.876, 1), (0.867, 25), (0.855, 27), (0.853, 6), (0.84, 11), (nan, 63), (nan, 67), (1.091, 71), (1.083, 77), (1.08, 92), (1.078, 54), (1.078, 70), (1.077, 65), (1.077, 81), (1.076, 68), (1.075, 96), (1.073, 55), (1.07, 58), (1.069, 57), (1.069, 76), (1.057, 86), (1.053, 88), (1.051, 94), (1.047, 66), (1.044, 91), (1.042, 60), (1.042, 75), (1.041, 98), (1.038, 51), (1.038, 52), (1.038, 59), (1.036, 62), (1.036, 84), (1.035, 56), (1.035, 89), (1.035, 93), (1.034, 82), (1.032, 72), (1.026, 53), (1.026, 69), (0.988, 97), (0.985, 64), (0.931, 73), (0.921, 85), (0.918, 95), (0.916, 99), (0.91, 74), (0.891, 78), (0.889, 61), (0.876, 50), (0.873, 90), (0.868, 79), (0.866, 87), (0.853, 83), (0.797, 80)]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgejoJlXJKNN",
        "outputId": "61164ffc-b190-49e4-e866-36cea129f0ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# Question number (d)\n",
        "# by using tf-idfs (tf => double normalization, idf => inverse frequency smooth) \n",
        "query_2_words = [\"indian city\", \"uttar pradesh\", \"state city\"]\n",
        "weight_dict_query, weight_dict_corpus = processQuery(query_2_words, tf_normalization_idf_inv_freq_smooth_matrix)\n",
        "generate_ranked_list(weight_dict_query, weight_dict_corpus)\n",
        "\n",
        "query_3_words = [\"indian city temple\", \"uttar pradesh people\", \"state city country\"]\n",
        "weight_dict_query, weight_dict_corpus = processQuery(query_3_words, tf_normalization_idf_inv_freq_smooth_matrix)\n",
        "generate_ranked_list(weight_dict_query, weight_dict_corpus)\n",
        "\n",
        "query_5_words = [\"indian city state current population\", \"uttar pradesh hindu heritage holy\", \"state capital city world population\"]\n",
        "weight_dict_query, weight_dict_corpus = processQuery(query_5_words, tf_normalization_idf_inv_freq_smooth_matrix)\n",
        "generate_ranked_list(weight_dict_query, weight_dict_corpus)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "indian city : [(0.925, 2), (0.925, 3), (0.925, 5), (0.925, 13), (0.925, 14), (0.925, 16), (0.925, 32), (0.925, 34), (0.925, 39), (0.925, 43), (0.925, 56), (0.925, 61), (0.925, 62), (0.35, 28), (0.335, 36), (0.323, 6), (0.297, 12), (0.275, 19), (0.273, 31), (0.261, 49), (0.255, 15), (0.247, 25), (0.247, 44), (0.233, 4), (0.233, 21), (0.233, 26), (0.232, 7), (0.232, 17), (0.232, 38), (0.232, 40), (0.224, 11), (0.218, 27), (0.205, 29), (0.203, 0), (0.203, 18), (0.203, 20), (0.203, 37), (0.203, 46), (0.203, 48), (0.188, 8), (0.188, 10), (0.188, 22), (0.188, 23), (0.188, 33), (0.188, 42), (0.188, 45), (0.18, 47), (0.173, 30), (0.172, 1), (0.167, 9), (0.164, 35), (0.15, 41), (0.089, 24), (nan, 63), (0.925, 65), (nan, 67), (0.925, 71), (0.925, 75), (0.925, 77), (0.925, 82), (0.925, 86), (0.925, 94), (0.925, 97), (0.925, 99), (0.335, 73), (0.31, 72), (0.31, 98), (0.275, 87), (0.275, 93), (0.268, 69), (0.266, 85), (0.261, 53), (0.261, 76), (0.261, 79), (0.261, 81), (0.26, 95), (0.247, 84), (0.247, 90), (0.247, 92), (0.246, 50), (0.238, 80), (0.232, 60), (0.232, 88), (0.22, 64), (0.22, 74), (0.22, 89), (0.218, 51), (0.218, 55), (0.206, 68), (0.205, 58), (0.203, 91), (0.203, 96), (0.192, 83), (0.188, 54), (0.188, 59), (0.188, 78), (0.184, 66), (0.183, 52), (0.174, 57), (0.164, 70)]\n",
            "uttar pradesh : [(0.436, 0), (nan, 2), (0.436, 4), (0.436, 5), (nan, 6), (nan, 7), (nan, 8), (nan, 9), (nan, 10), (nan, 11), (nan, 12), (nan, 14), (0.436, 15), (0.0, 13), (nan, 16), (nan, 18), (nan, 19), (nan, 20), (0.436, 21), (0.0, 17), (nan, 22), (nan, 23), (nan, 24), (nan, 26), (0.002, 28), (0.0, 3), (0.0, 27), (nan, 29), (nan, 30), (0.436, 31), (nan, 32), (nan, 33), (nan, 34), (nan, 35), (nan, 36), (0.436, 37), (0.003, 25), (0.0, 1), (nan, 38), (nan, 39), (nan, 40), (nan, 41), (nan, 42), (nan, 43), (nan, 44), (0.436, 49), (0.174, 47), (0.003, 46), (0.001, 45), (0.0, 48), (nan, 51), (nan, 52), (nan, 53), (0.436, 54), (nan, 57), (0.436, 58), (0.174, 56), (nan, 59), (nan, 60), (nan, 61), (nan, 62), (nan, 63), (nan, 64), (nan, 65), (0.436, 66), (0.006, 55), (nan, 67), (nan, 68), (nan, 69), (nan, 70), (nan, 71), (nan, 72), (nan, 73), (0.436, 75), (0.002, 74), (0.0, 50), (nan, 76), (nan, 77), (nan, 78), (nan, 79), (nan, 80), (nan, 81), (nan, 82), (nan, 83), (0.436, 85), (0.003, 84), (0.0, 86), (nan, 87), (nan, 88), (0.436, 89), (nan, 90), (nan, 91), (0.001, 92), (nan, 93), (nan, 94), (0.436, 95), (nan, 96), (0.002, 97), (nan, 98), (nan, 99)]\n",
            "state city : [(0.757, 3), (0.757, 14), (0.757, 20), (0.757, 38), (0.257, 11), (0.257, 36), (0.246, 6), (0.218, 31), (0.205, 32), (0.198, 43), (0.193, 29), (0.18, 25), (0.169, 19), (0.168, 7), (0.168, 47), (0.158, 21), (0.158, 49), (0.146, 1), (0.143, 5), (0.143, 46), (0.143, 48), (0.135, 24), (0.132, 4), (0.13, 2), (0.13, 8), (0.13, 12), (0.13, 13), (0.13, 23), (0.13, 28), (0.13, 33), (0.13, 42), (0.13, 45), (0.124, 9), (0.124, 34), (0.122, 44), (0.117, 16), (0.112, 18), (0.112, 37), (0.112, 39), (0.111, 17), (0.111, 40), (0.106, 26), (0.103, 15), (0.101, 10), (0.101, 35), (0.091, 0), (0.089, 30), (0.078, 27), (0.071, 41), (0.061, 22), (nan, 63), (nan, 67), (0.757, 86), (0.757, 88), (0.235, 72), (0.224, 69), (0.205, 50), (0.205, 57), (0.193, 79), (0.18, 64), (0.18, 80), (0.18, 89), (0.176, 56), (0.17, 85), (0.169, 93), (0.169, 99), (0.158, 53), (0.155, 62), (0.155, 83), (0.146, 74), (0.146, 84), (0.146, 90), (0.146, 92), (0.146, 97), (0.143, 96), (0.137, 52), (0.132, 76), (0.13, 59), (0.124, 51), (0.124, 55), (0.124, 95), (0.12, 91), (0.12, 98), (0.117, 71), (0.117, 94), (0.116, 73), (0.115, 87), (0.111, 60), (0.111, 68), (0.106, 58), (0.101, 65), (0.101, 78), (0.089, 66), (0.089, 77), (0.089, 81), (0.081, 54), (0.081, 70), (0.071, 82), (0.064, 61), (0.064, 75)]\n",
            "\n",
            "indian city temple : [(0.986, 2), (0.986, 3), (0.986, 5), (0.986, 13), (0.986, 14), (0.986, 16), (0.986, 32), (0.986, 34), (0.986, 39), (0.986, 43), (0.986, 56), (0.986, 61), (0.986, 62), (0.879, 28), (0.876, 36), (0.874, 6), (0.869, 12), (0.865, 31), (0.863, 49), (0.862, 15), (0.86, 25), (0.857, 4), (0.857, 7), (0.857, 17), (0.857, 38), (0.856, 11), (0.855, 27), (0.852, 0), (0.852, 18), (0.852, 20), (0.852, 29), (0.852, 37), (0.852, 46), (0.849, 8), (0.849, 10), (0.849, 23), (0.849, 33), (0.849, 42), (0.847, 47), (0.846, 1), (0.846, 30), (0.845, 9), (0.845, 35), (0.842, 41), (0.831, 24), (0.125, 26), (0.112, 44), (0.106, 40), (0.095, 21), (0.089, 22), (0.07, 48), (0.066, 45), (0.042, 19), (nan, 63), (0.986, 65), (nan, 67), (0.986, 71), (0.986, 75), (0.986, 77), (0.986, 82), (0.986, 86), (0.986, 94), (0.986, 97), (0.986, 99), (0.865, 87), (0.865, 93), (0.864, 85), (0.863, 76), (0.863, 79), (0.863, 95), (0.86, 84), (0.86, 90), (0.858, 80), (0.855, 55), (0.855, 64), (0.855, 74), (0.852, 58), (0.852, 68), (0.852, 96), (0.85, 83), (0.849, 54), (0.849, 59), (0.848, 66), (0.846, 57), (0.845, 70), (0.198, 52), (0.169, 91), (0.156, 73), (0.142, 72), (0.141, 69), (0.119, 89), (0.118, 81), (0.112, 92), (0.11, 98), (0.106, 60), (0.1, 51), (0.089, 78), (0.08, 88), (0.058, 53), (0.052, 50)]\n",
            "uttar pradesh people : [(0.619, 0), (nan, 2), (0.619, 4), (0.619, 5), (0.325, 1), (0.325, 3), (nan, 7), (nan, 8), (nan, 9), (nan, 10), (nan, 11), (nan, 12), (nan, 14), (nan, 16), (nan, 19), (0.619, 21), (0.325, 13), (0.262, 6), (0.262, 18), (0.262, 20), (0.175, 15), (nan, 22), (nan, 23), (nan, 24), (0.326, 28), (0.325, 17), (0.262, 26), (0.02, 27), (nan, 29), (nan, 30), (0.619, 31), (nan, 32), (nan, 33), (nan, 34), (nan, 35), (nan, 36), (0.619, 37), (0.327, 25), (nan, 38), (nan, 39), (nan, 40), (nan, 41), (nan, 42), (nan, 43), (nan, 44), (0.619, 49), (0.443, 47), (0.327, 46), (0.326, 45), (0.02, 48), (nan, 51), (nan, 52), (0.619, 54), (0.262, 53), (nan, 57), (0.619, 58), (0.443, 56), (0.325, 50), (nan, 59), (nan, 60), (nan, 61), (nan, 62), (nan, 63), (nan, 64), (nan, 65), (0.619, 66), (0.329, 55), (nan, 67), (nan, 68), (nan, 70), (nan, 71), (nan, 72), (nan, 73), (0.619, 75), (0.326, 74), (nan, 76), (nan, 77), (nan, 78), (nan, 79), (nan, 81), (nan, 83), (0.619, 85), (0.327, 84), (0.325, 86), (0.262, 80), (0.262, 82), (nan, 87), (nan, 88), (0.619, 89), (nan, 90), (nan, 91), (0.326, 92), (0.262, 69), (nan, 93), (nan, 94), (0.619, 95), (nan, 96), (0.326, 97), (nan, 98), (nan, 99)]\n",
            "state city country : [(0.99, 3), (0.99, 14), (0.99, 20), (0.99, 38), (0.969, 11), (0.969, 36), (0.968, 6), (0.967, 31), (0.967, 32), (0.966, 25), (0.966, 29), (0.965, 7), (0.965, 19), (0.965, 21), (0.965, 47), (0.964, 1), (0.964, 4), (0.964, 5), (0.964, 24), (0.964, 46), (0.964, 48), (0.963, 2), (0.963, 8), (0.963, 9), (0.963, 13), (0.963, 16), (0.963, 17), (0.963, 18), (0.963, 23), (0.963, 33), (0.963, 34), (0.963, 37), (0.963, 39), (0.963, 40), (0.963, 42), (0.963, 44), (0.963, 45), (0.962, 0), (0.962, 10), (0.962, 15), (0.962, 26), (0.962, 30), (0.962, 35), (0.961, 22), (0.961, 27), (0.961, 41), (0.08, 28), (0.051, 12), (0.044, 43), (0.037, 49), (nan, 63), (nan, 67), (0.99, 86), (0.99, 88), (0.968, 72), (0.967, 50), (0.967, 57), (0.967, 69), (0.966, 79), (0.966, 89), (0.965, 53), (0.965, 56), (0.965, 93), (0.965, 99), (0.964, 52), (0.964, 74), (0.964, 76), (0.964, 83), (0.964, 84), (0.964, 90), (0.964, 92), (0.964, 96), (0.964, 97), (0.963, 51), (0.963, 55), (0.963, 59), (0.963, 68), (0.963, 71), (0.963, 91), (0.963, 94), (0.963, 95), (0.963, 98), (0.962, 65), (0.962, 66), (0.962, 77), (0.962, 78), (0.961, 54), (0.961, 61), (0.961, 70), (0.961, 75), (0.961, 82), (0.07, 85), (0.066, 73), (0.05, 80), (0.05, 81), (0.048, 87), (0.046, 58), (0.037, 60), (0.032, 64), (0.028, 62)]\n",
            "\n",
            "indian city state current population : [(0.994, 3), (0.98, 32), (0.979, 43), (0.978, 2), (0.978, 5), (0.978, 13), (0.978, 34), (0.977, 16), (0.936, 19), (0.936, 38), (0.935, 17), (0.935, 26), (0.935, 31), (0.934, 4), (0.934, 20), (0.934, 22), (0.933, 7), (0.931, 46), (0.931, 48), (0.93, 8), (0.93, 23), (0.93, 29), (0.93, 33), (0.93, 41), (0.929, 9), (0.929, 35), (0.928, 1), (0.809, 28), (0.789, 12), (0.785, 36), (0.778, 49), (0.775, 0), (0.773, 11), (0.773, 14), (0.773, 25), (0.773, 47), (0.771, 18), (0.771, 24), (0.771, 37), (0.77, 10), (0.766, 42), (0.766, 45), (0.765, 21), (0.765, 40), (0.76, 6), (0.758, 27), (0.757, 30), (0.06, 15), (0.051, 39), (0.019, 44), (nan, 63), (nan, 67), (0.994, 86), (0.979, 99), (0.978, 62), (0.977, 65), (0.977, 71), (0.977, 77), (0.976, 75), (0.938, 81), (0.936, 76), (0.936, 88), (0.936, 93), (0.936, 95), (0.935, 79), (0.934, 84), (0.934, 92), (0.933, 51), (0.933, 55), (0.933, 58), (0.932, 54), (0.932, 68), (0.932, 74), (0.931, 78), (0.931, 96), (0.93, 59), (0.93, 70), (0.93, 83), (0.927, 57), (0.815, 56), (0.801, 61), (0.794, 98), (0.79, 66), (0.788, 85), (0.787, 87), (0.785, 73), (0.784, 52), (0.782, 72), (0.78, 91), (0.778, 60), (0.778, 94), (0.776, 90), (0.774, 82), (0.774, 89), (0.769, 97), (0.767, 69), (0.757, 80), (0.756, 53), (0.752, 64), (0.018, 50)]\n",
            "uttar pradesh hindu heritage holy : [(0.744, 0), (nan, 2), (0.744, 5), (0.601, 6), (nan, 7), (nan, 8), (nan, 9), (nan, 11), (nan, 12), (nan, 14), (nan, 18), (0.601, 19), (0.573, 16), (0.547, 1), (0.547, 13), (0.547, 17), (0.527, 4), (nan, 20), (0.503, 21), (0.367, 15), (0.2, 3), (nan, 22), (nan, 23), (nan, 24), (nan, 26), (0.547, 27), (0.105, 28), (nan, 29), (nan, 30), (0.744, 31), (0.601, 10), (nan, 32), (nan, 33), (nan, 34), (nan, 35), (nan, 36), (0.744, 37), (0.548, 25), (nan, 38), (nan, 39), (nan, 40), (nan, 41), (nan, 42), (nan, 43), (0.744, 49), (0.573, 44), (0.547, 48), (0.378, 46), (0.148, 47), (0.012, 45), (nan, 51), (nan, 52), (0.744, 54), (nan, 57), (0.744, 58), (nan, 59), (nan, 62), (nan, 64), (nan, 65), (0.744, 66), (nan, 67), (nan, 68), (nan, 69), (nan, 70), (nan, 71), (nan, 72), (0.744, 75), (nan, 76), (nan, 77), (nan, 78), (nan, 79), (0.601, 81), (nan, 82), (nan, 83), (0.744, 85), (0.601, 61), (0.601, 63), (0.601, 88), (0.573, 60), (0.573, 73), (0.573, 80), (0.573, 87), (0.55, 55), (0.548, 84), (0.547, 86), (0.529, 89), (0.445, 56), (0.38, 74), (nan, 90), (0.601, 91), (0.547, 92), (0.43, 53), (0.107, 50), (nan, 93), (nan, 94), (0.744, 95), (0.573, 96), (0.409, 97), (nan, 98), (0.573, 99)]\n",
            "state capital city world population : [(0.987, 3), (0.959, 32), (0.957, 7), (0.956, 5), (0.956, 48), (0.956, 62), (0.955, 23), (0.955, 33), (0.955, 51), (0.952, 41), (0.879, 31), (0.876, 43), (0.873, 26), (0.871, 38), (0.866, 19), (0.866, 20), (0.865, 9), (0.865, 34), (0.863, 17), (0.862, 35), (0.859, 2), (0.859, 8), (0.859, 13), (0.858, 16), (0.858, 39), (0.576, 12), (0.57, 36), (0.57, 37), (0.557, 42), (0.557, 44), (0.548, 0), (0.544, 47), (0.542, 14), (0.54, 18), (0.538, 10), (0.529, 45), (0.526, 21), (0.526, 24), (0.526, 40), (0.51, 30), (0.316, 4), (0.315, 15), (0.301, 22), (0.288, 46), (0.285, 29), (0.253, 1), (0.216, 28), (0.126, 49), (0.115, 27), (0.113, 25), (0.1, 6), (0.086, 11), (nan, 63), (nan, 67), (0.957, 93), (0.956, 84), (0.955, 59), (0.952, 75), (0.873, 58), (0.871, 76), (0.871, 88), (0.866, 86), (0.865, 55), (0.865, 57), (0.865, 81), (0.864, 54), (0.864, 70), (0.863, 68), (0.862, 65), (0.861, 96), (0.855, 77), (0.854, 92), (0.845, 71), (0.592, 56), (0.585, 98), (0.576, 66), (0.561, 52), (0.56, 72), (0.558, 91), (0.554, 60), (0.543, 89), (0.536, 94), (0.534, 97), (0.529, 64), (0.529, 69), (0.516, 82), (0.508, 53), (0.311, 95), (0.304, 99), (0.295, 74), (0.295, 79), (0.279, 83), (0.273, 78), (0.208, 73), (0.188, 85), (0.148, 61), (0.122, 50), (0.122, 90), (0.118, 87), (0.062, 80)]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "446-R8O2qIrx"
      },
      "source": [
        "\n",
        "def generate_vector(value):\n",
        "    val = 0\n",
        "    for v in value:\n",
        "        val += v**2\n",
        "    return val**0.5\n",
        "\n",
        "def write_vectors_in_csv(value, filename):\n",
        "\n",
        "    with open(f'{filename}.csv',\"w\", newline = \"\") as csv_writer:\n",
        "        writer = csv.writer(csv_writer)\n",
        "        writer.writerow([\"Keyword\",\"Vector Value\"])\n",
        "        for i in range(len(value)):\n",
        "            writer.writerow([i,value[i]])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETLC4ZTqorga"
      },
      "source": [
        "# calculation of different variants of tf-idfs by converting them into vectors\n",
        "tf_log_idf_inv_freq_smooth_vector = []\n",
        "for key, value in tf_log_idf_inv_freq_smooth_matrix.items():\n",
        "    tf_log_idf_inv_freq_smooth_vector.append( generate_vector(value) )\n",
        "    write_vectors_in_csv(tf_log_idf_inv_freq_smooth_vector, \"tf_idf_log_inv_freq_smooth\")\n",
        "\n",
        "tf_log_idf_prob_inv_freq_vector = []\n",
        "for key, value in tf_log_idf_prob_inv_freq_matrix.items():\n",
        "    tf_log_idf_prob_inv_freq_vector.append( generate_vector(value) )\n",
        "    write_vectors_in_csv(tf_log_idf_prob_inv_freq_vector, \"tf_idf_log_prob_inv_freq\")\n",
        "\n",
        "tf_normalization_idf_inv_freq_smooth_vector = []\n",
        "for key, value in tf_normalization_idf_inv_freq_smooth_matrix.items():\n",
        "    tf_normalization_idf_inv_freq_smooth_vector.append( generate_vector(value) )\n",
        "    write_vectors_in_csv(tf_normalization_idf_inv_freq_smooth_vector, \"tf_idf_norm_inv_freq_smooth\")\n",
        "\n",
        "tf_normalization_idf_prob_inv_freq_vector = []\n",
        "for key, value in tf_normalization_idf_prob_inv_freq_matrix.items():\n",
        "    tf_normalization_idf_prob_inv_freq_vector.append( generate_vector(value) )\n",
        "    write_vectors_in_csv(tf_normalization_idf_prob_inv_freq_vector, \"tf_idf_norm_prob_inv_freq\")"
      ],
      "execution_count": 49,
      "outputs": []
    }
  ]
}